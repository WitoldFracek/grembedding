{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_VECTORIZERS = [\n",
    "    \"BigramMorphTagVectorizer100\",\n",
    "    \"BigramMorphTagVectorizer370\",\n",
    "    \"CountVectorizer1000\",\n",
    "    \"CountVectorizer5000\",\n",
    "    \"DPEBPVectorizer100Avg\",\n",
    "    \"FullMorphTagVectorizer\",\n",
    "    \"HerbertVectorizer\",\n",
    "    \"SpacyMorphTagVectorizer\",\n",
    "    \"StyloMetrix\",\n",
    "    \"TfidfVectorizer1000\",\n",
    "    \"TfidfVectorizer5000\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Task(Enum):\n",
    "    classification = 1\n",
    "    clustering = 2\n",
    "\n",
    "DATALOADERS_DATACLEANERS = [\n",
    "    (\"TweeterCyberbullying\", \"DummyDatacleaner\", [Task.classification]),\n",
    "    (\"PrusVsSienkiewicz\", \"DummyDatacleaner\", [Task.classification])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCLUDES = {\n",
    "    # \"TweeterCyberbullying\" : [\"HerbertVectorizer\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = []\n",
    "clean = []\n",
    "vectorize = []\n",
    "evaluate_classification = []\n",
    "evaluate_clustering = []\n",
    "\n",
    "for dataloader, datacleaner, tasks in DATALOADERS_DATACLEANERS:\n",
    "    load.append({\n",
    "        \"dataloader\": dataloader\n",
    "    })\n",
    "    clean.append({\n",
    "        \"dataloader\": dataloader,\n",
    "        \"datacleaner\": datacleaner\n",
    "    })\n",
    "    excluded = EXCLUDES.get(dataloader, [])\n",
    "\n",
    "    for vectorizer in ALL_VECTORIZERS:\n",
    "        if vectorizer in excluded:\n",
    "            continue\n",
    "        vectorize_params = {\n",
    "            \"dataloader\": dataloader,\n",
    "            \"datacleaner\": datacleaner,\n",
    "            \"vectorizer\": vectorizer\n",
    "        }\n",
    "        vectorize.append(vectorize_params.copy())\n",
    "        if Task.classification in tasks:\n",
    "            evaluate_classification.append(vectorize_params.copy())\n",
    "        if Task.clustering in tasks:\n",
    "            evaluate_clustering.append(vectorize_params.copy())\n",
    "\n",
    "params = {\n",
    "    \"load\": load,\n",
    "    \"clean\": clean,\n",
    "    \"vectorize\": vectorize,\n",
    "    \"evaluate_classification\": evaluate_classification,\n",
    "    \"evaluate_clustering\": evaluate_clustering\n",
    "}\n",
    "\n",
    "with open(\"./models.yaml\", 'r') as file:\n",
    "    models = yaml.safe_load(file)\n",
    "\n",
    "for key in models.keys():\n",
    "    params[key] = models[key]\n",
    "\n",
    "with open(\"./generated_params.yaml\", \"w\") as file:\n",
    "    yaml.dump(params, file, default_flow_style=False, sort_keys=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
