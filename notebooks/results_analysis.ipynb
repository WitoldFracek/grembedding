{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from notebooks.results import load_results, classification, clusterization, to_latex_table, GremDataFrame\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_letters(s: str) -> str:\n",
    "    return re.findall(r'[a-zA-Z]+', s)[0]\n",
    "\n",
    "def fix_dataset_name(s: str) -> str:\n",
    "    return {\n",
    "        'TweeterCyberbullying': 'TwitterCyberbullying'\n",
    "    }.get(s, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>datacleaner</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>params_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>davies_bouldin</th>\n",
       "      <th>calinski_harabasz</th>\n",
       "      <th>bcubed_precission</th>\n",
       "      <th>bcubed_recall</th>\n",
       "      <th>bcubed_f1</th>\n",
       "      <th>base_head_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TwitterCyberbullying</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>MLP1</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>0.477922</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.457711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TwitterCyberbullying</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>MLP2</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>0.477922</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.457711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TwitterCyberbullying</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>MLP3</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>0.541487</td>\n",
       "      <td>0.53312</td>\n",
       "      <td>0.760302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TwitterCyberbullying</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>RandomForest1</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>0.477922</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.457711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TwitterCyberbullying</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>KMeans1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086742</td>\n",
       "      <td>3.113713</td>\n",
       "      <td>889.408505</td>\n",
       "      <td>0.845114</td>\n",
       "      <td>0.501334</td>\n",
       "      <td>0.629336</td>\n",
       "      <td>KMeans</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset       datacleaner               vectorizer  \\\n",
       "0  TwitterCyberbullying  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "1  TwitterCyberbullying  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "2  TwitterCyberbullying  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "3  TwitterCyberbullying  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "4  TwitterCyberbullying  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "\n",
       "     params_name  accuracy  f1_score   recall  precision  silhouette  \\\n",
       "0           MLP1  0.915423  0.477922  0.50000   0.457711         NaN   \n",
       "1           MLP2  0.915423  0.477922  0.50000   0.457711         NaN   \n",
       "2           MLP3  0.917413  0.541487  0.53312   0.760302         NaN   \n",
       "3  RandomForest1  0.915423  0.477922  0.50000   0.457711         NaN   \n",
       "4      KMeans1.0       NaN       NaN      NaN        NaN    0.086742   \n",
       "\n",
       "   davies_bouldin  calinski_harabasz  bcubed_precission  bcubed_recall  \\\n",
       "0             NaN                NaN                NaN            NaN   \n",
       "1             NaN                NaN                NaN            NaN   \n",
       "2             NaN                NaN                NaN            NaN   \n",
       "3             NaN                NaN                NaN            NaN   \n",
       "4        3.113713         889.408505           0.845114       0.501334   \n",
       "\n",
       "   bcubed_f1 base_head_model  \n",
       "0        NaN             MLP  \n",
       "1        NaN             MLP  \n",
       "2        NaN             MLP  \n",
       "3        NaN    RandomForest  \n",
       "4   0.629336          KMeans  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results_df = load_results('../results')\n",
    "results_df = GremDataFrame(load_results('../results/'))\n",
    "results_df['dataset'] = results_df['dataset'].apply(fix_dataset_name)\n",
    "results_df['base_head_model'] = results_df['params_name'].apply(extract_letters)\n",
    "print(len(results_df))\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TwitterCyberbullying', 'PrusVsSienkiewicz', 'WritingStyle',\n",
       "       'Classics5Authors35Books', 'OldNewspapers', 'StarWarsFanfic',\n",
       "       'EroticVsOthers', 'StarWarsFanficShort'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['dataset'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>Classics5Authors35Books</th>\n",
       "      <th>EroticVsOthers</th>\n",
       "      <th>OldNewspapers</th>\n",
       "      <th>PrusVsSienkiewicz</th>\n",
       "      <th>StarWarsFanfic</th>\n",
       "      <th>StarWarsFanficShort</th>\n",
       "      <th>TwitterCyberbullying</th>\n",
       "      <th>WritingStyle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vectorizer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BigramMorphTagVectorizer100</th>\n",
       "      <td>0.861</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigramMorphTagVectorizer370</th>\n",
       "      <td>0.891</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer1000</th>\n",
       "      <td>0.902</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer5000</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DPEBPVectorizer100Avg</th>\n",
       "      <td>0.616</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullMorphTagVectorizer</th>\n",
       "      <td>0.729</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpacyMorphTagVectorizer</th>\n",
       "      <td>0.737</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.128</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer1000</th>\n",
       "      <td>0.909</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer5000</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.837</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.745</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                      Classics5Authors35Books  EroticVsOthers  \\\n",
       "vectorizer                                                             \n",
       "BigramMorphTagVectorizer100                    0.861           0.597   \n",
       "BigramMorphTagVectorizer370                    0.891           0.593   \n",
       "CountVectorizer1000                            0.902           0.645   \n",
       "CountVectorizer5000                            0.858           0.657   \n",
       "DPEBPVectorizer100Avg                          0.616           0.622   \n",
       "FullMorphTagVectorizer                         0.729           0.599   \n",
       "SpacyMorphTagVectorizer                        0.737           0.598   \n",
       "TfidfVectorizer1000                            0.909           0.645   \n",
       "TfidfVectorizer5000                            0.858           0.658   \n",
       "\n",
       "dataset                      OldNewspapers  PrusVsSienkiewicz  StarWarsFanfic  \\\n",
       "vectorizer                                                                      \n",
       "BigramMorphTagVectorizer100          0.099              0.743           0.975   \n",
       "BigramMorphTagVectorizer370          0.114              0.750           0.841   \n",
       "CountVectorizer1000                  0.117              0.836           0.975   \n",
       "CountVectorizer5000                  0.166              0.844           0.975   \n",
       "DPEBPVectorizer100Avg                0.149              0.649           0.939   \n",
       "FullMorphTagVectorizer               0.119              0.778           0.902   \n",
       "SpacyMorphTagVectorizer              0.128              0.832           0.902   \n",
       "TfidfVectorizer1000                  0.122              0.842           0.951   \n",
       "TfidfVectorizer5000                  0.165              0.837           1.000   \n",
       "\n",
       "dataset                      StarWarsFanficShort  TwitterCyberbullying  \\\n",
       "vectorizer                                                               \n",
       "BigramMorphTagVectorizer100                0.686                 0.550   \n",
       "BigramMorphTagVectorizer370                0.697                 0.618   \n",
       "CountVectorizer1000                        0.736                 0.626   \n",
       "CountVectorizer5000                        0.745                 0.713   \n",
       "DPEBPVectorizer100Avg                      0.762                 0.498   \n",
       "FullMorphTagVectorizer                     0.721                 0.667   \n",
       "SpacyMorphTagVectorizer                    0.716                 0.541   \n",
       "TfidfVectorizer1000                        0.731                 0.656   \n",
       "TfidfVectorizer5000                        0.745                 0.710   \n",
       "\n",
       "dataset                      WritingStyle  \n",
       "vectorizer                                 \n",
       "BigramMorphTagVectorizer100         0.537  \n",
       "BigramMorphTagVectorizer370         0.544  \n",
       "CountVectorizer1000                 0.657  \n",
       "CountVectorizer5000                 0.672  \n",
       "DPEBPVectorizer100Avg               0.588  \n",
       "FullMorphTagVectorizer              0.574  \n",
       "SpacyMorphTagVectorizer             0.524  \n",
       "TfidfVectorizer1000                 0.666  \n",
       "TfidfVectorizer5000                 0.687  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "vecs = list(results_df['vectorizer'].unique())\n",
    "vecs.remove('HerbertVectorizer')\n",
    "\n",
    "(\n",
    "    results_df\n",
    "    .classification()\n",
    "    .vectorizer(vecs)\n",
    "    .sort_values('f1_score', ascending=False)\n",
    "    .drop_duplicates(subset=['dataset', 'vectorizer'])\n",
    "    .drop(columns=list(results_df.columns[6:-1]) + ['datacleaner', 'params_name'])\n",
    "    .pivot(index='vectorizer', columns='dataset', values='f1_score')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset', 'datacleaner', 'vectorizer', 'params_name', 'accuracy',\n",
       "       'f1_score', 'recall', 'precision', 'silhouette', 'davies_bouldin',\n",
       "       'calinski_harabasz', 'bcubed_precission', 'bcubed_recall', 'bcubed_f1',\n",
       "       'base_head_model'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = ['datacleaner', 'params_name', 'accuracy',\n",
    "       'f1_score', 'recall', 'precision', 'silhouette', 'davies_bouldin',\n",
    "       'calinski_harabasz', 'bcubed_precission', 'bcubed_recall',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>dataset</th>\n",
       "      <th>Classics5Authors35Books</th>\n",
       "      <th>EroticVsOthers</th>\n",
       "      <th>OldNewspapers</th>\n",
       "      <th>PrusVsSienkiewicz</th>\n",
       "      <th>StarWarsFanfic</th>\n",
       "      <th>StarWarsFanficShort</th>\n",
       "      <th>TwitterCyberbullying</th>\n",
       "      <th>WritingStyle</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vectorizer</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BigramMorphTagVectorizer100</th>\n",
       "      <td>0.407</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.154</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BigramMorphTagVectorizer370</th>\n",
       "      <td>0.407</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer1000</th>\n",
       "      <td>0.407</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CountVectorizer5000</th>\n",
       "      <td>0.407</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DPEBPVectorizer100Avg</th>\n",
       "      <td>0.409</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FullMorphTagVectorizer</th>\n",
       "      <td>0.407</td>\n",
       "      <td>0.516</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.903</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SpacyMorphTagVectorizer</th>\n",
       "      <td>0.407</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer1000</th>\n",
       "      <td>0.459</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TfidfVectorizer5000</th>\n",
       "      <td>0.531</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.158</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                      Classics5Authors35Books  EroticVsOthers  \\\n",
       "vectorizer                                                             \n",
       "BigramMorphTagVectorizer100                    0.407           0.658   \n",
       "BigramMorphTagVectorizer370                    0.407           0.519   \n",
       "CountVectorizer1000                            0.407           0.678   \n",
       "CountVectorizer5000                            0.407           0.678   \n",
       "DPEBPVectorizer100Avg                          0.409           0.596   \n",
       "FullMorphTagVectorizer                         0.407           0.516   \n",
       "SpacyMorphTagVectorizer                        0.407           0.678   \n",
       "TfidfVectorizer1000                            0.459           0.678   \n",
       "TfidfVectorizer5000                            0.531           0.678   \n",
       "\n",
       "dataset                      OldNewspapers  PrusVsSienkiewicz  StarWarsFanfic  \\\n",
       "vectorizer                                                                      \n",
       "BigramMorphTagVectorizer100          0.154              0.664           0.657   \n",
       "BigramMorphTagVectorizer370          0.158              0.534           0.560   \n",
       "CountVectorizer1000                  0.160              0.667           0.668   \n",
       "CountVectorizer5000                  0.158              0.667           0.668   \n",
       "DPEBPVectorizer100Avg                0.157              0.624           0.580   \n",
       "FullMorphTagVectorizer               0.160              0.568           0.622   \n",
       "SpacyMorphTagVectorizer              0.157              0.667           0.665   \n",
       "TfidfVectorizer1000                  0.160              0.698           0.751   \n",
       "TfidfVectorizer5000                  0.158              0.986           0.737   \n",
       "\n",
       "dataset                      StarWarsFanficShort  TwitterCyberbullying  \\\n",
       "vectorizer                                                               \n",
       "BigramMorphTagVectorizer100                0.584                 0.820   \n",
       "BigramMorphTagVectorizer370                0.628                 0.893   \n",
       "CountVectorizer1000                        0.618                 0.903   \n",
       "CountVectorizer5000                        0.667                 0.914   \n",
       "DPEBPVectorizer100Avg                      0.640                 0.907   \n",
       "FullMorphTagVectorizer                     0.633                 0.903   \n",
       "SpacyMorphTagVectorizer                    0.640                 0.885   \n",
       "TfidfVectorizer1000                        0.616                 0.887   \n",
       "TfidfVectorizer5000                        0.665                 0.913   \n",
       "\n",
       "dataset                      WritingStyle  \n",
       "vectorizer                                 \n",
       "BigramMorphTagVectorizer100         0.680  \n",
       "BigramMorphTagVectorizer370         0.677  \n",
       "CountVectorizer1000                 0.684  \n",
       "CountVectorizer5000                 0.684  \n",
       "DPEBPVectorizer100Avg               0.671  \n",
       "FullMorphTagVectorizer              0.678  \n",
       "SpacyMorphTagVectorizer             0.684  \n",
       "TfidfVectorizer1000                 0.684  \n",
       "TfidfVectorizer5000                 0.684  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.float_format = '{:,.3f}'.format\n",
    "vecs = list(results_df['vectorizer'].unique())\n",
    "vecs.remove('HerbertVectorizer')\n",
    "\n",
    "(\n",
    "    results_df\n",
    "    .clusterization()\n",
    "    .vectorizer(vecs)\n",
    "    .sort_values('bcubed_f1', ascending=False)\n",
    "    .drop_duplicates(subset=['dataset', 'vectorizer'])\n",
    "    .drop(columns=to_drop)\n",
    "    .pivot(index='vectorizer', columns='dataset', values='bcubed_f1')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>datacleaner</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>params_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>davies_bouldin</th>\n",
       "      <th>calinski_harabasz</th>\n",
       "      <th>bcubed_precission</th>\n",
       "      <th>bcubed_recall</th>\n",
       "      <th>bcubed_f1</th>\n",
       "      <th>base_head_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>PrusVsSienkiewicz</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>RandomForest1</td>\n",
       "      <td>0.852688</td>\n",
       "      <td>0.831615</td>\n",
       "      <td>0.832492</td>\n",
       "      <td>0.830762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>PrusVsSienkiewicz</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>MLP1</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.727253</td>\n",
       "      <td>0.737683</td>\n",
       "      <td>0.721667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>PrusVsSienkiewicz</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>MLP2</td>\n",
       "      <td>0.781720</td>\n",
       "      <td>0.761466</td>\n",
       "      <td>0.776675</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>PrusVsSienkiewicz</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>MLP3</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.777115</td>\n",
       "      <td>0.785746</td>\n",
       "      <td>0.771183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>StarWarsFanfic</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>RandomForest1</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.901502</td>\n",
       "      <td>0.899821</td>\n",
       "      <td>0.907599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>StarWarsFanfic</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>MLP1</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>0.851449</td>\n",
       "      <td>0.849732</td>\n",
       "      <td>0.862709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>StarWarsFanfic</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>MLP2</td>\n",
       "      <td>0.865854</td>\n",
       "      <td>0.864218</td>\n",
       "      <td>0.862552</td>\n",
       "      <td>0.872549</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>StarWarsFanfic</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>MLP3</td>\n",
       "      <td>0.890244</td>\n",
       "      <td>0.889438</td>\n",
       "      <td>0.888193</td>\n",
       "      <td>0.893116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset       datacleaner               vectorizer  \\\n",
       "85   PrusVsSienkiewicz  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "86   PrusVsSienkiewicz  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "87   PrusVsSienkiewicz  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "88   PrusVsSienkiewicz  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "311     StarWarsFanfic  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "313     StarWarsFanfic  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "314     StarWarsFanfic  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "315     StarWarsFanfic  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "\n",
       "       params_name  accuracy  f1_score    recall  precision  silhouette  \\\n",
       "85   RandomForest1  0.852688  0.831615  0.832492   0.830762         NaN   \n",
       "86            MLP1  0.752688  0.727253  0.737683   0.721667         NaN   \n",
       "87            MLP2  0.781720  0.761466  0.776675   0.754386         NaN   \n",
       "88            MLP3  0.800000  0.777115  0.785746   0.771183         NaN   \n",
       "311  RandomForest1  0.902439  0.901502  0.899821   0.907599         NaN   \n",
       "313           MLP1  0.853659  0.851449  0.849732   0.862709         NaN   \n",
       "314           MLP2  0.865854  0.864218  0.862552   0.872549         NaN   \n",
       "315           MLP3  0.890244  0.889438  0.888193   0.893116         NaN   \n",
       "\n",
       "     davies_bouldin  calinski_harabasz  bcubed_precission  bcubed_recall  \\\n",
       "85              NaN                NaN                NaN            NaN   \n",
       "86              NaN                NaN                NaN            NaN   \n",
       "87              NaN                NaN                NaN            NaN   \n",
       "88              NaN                NaN                NaN            NaN   \n",
       "311             NaN                NaN                NaN            NaN   \n",
       "313             NaN                NaN                NaN            NaN   \n",
       "314             NaN                NaN                NaN            NaN   \n",
       "315             NaN                NaN                NaN            NaN   \n",
       "\n",
       "     bcubed_f1 base_head_model  \n",
       "85         NaN    RandomForest  \n",
       "86         NaN             MLP  \n",
       "87         NaN             MLP  \n",
       "88         NaN             MLP  \n",
       "311        NaN    RandomForest  \n",
       "313        NaN             MLP  \n",
       "314        NaN             MLP  \n",
       "315        NaN             MLP  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    results_df\n",
    "    .dataset(['PrusVsSienkiewicz', 'StarWarsFanfic'])\n",
    "    .data_cleaner('DummyDatacleaner')\n",
    "    .vectorizer('SpacyMorphTagVectorizer')\n",
    "    .classification()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\t\\centering\n",
      "\t\\begin{tabular}{||c|c|c|c||}\n",
      "\t\t\\hline\n",
      "\t\tvectorizer & accuracy & f1 score & base head model \\\\\n",
      "\t\t\\hline\\hline\n",
      "\t\tCountVectorizer5000 & \\textbf{0.86} & \\textbf{0.84} & RandomForest \\\\\n",
      "\t\tTfidfVectorizer1000 & 0.85 & \\textbf{0.84} & MLP \\\\\n",
      "\t\tTfidfVectorizer5000 & 0.85 & \\textbf{0.84} & RandomForest \\\\\n",
      "\t\tCountVectorizer1000 & 0.85 & \\textbf{0.84} & MLP \\\\\n",
      "\t\tSpacyMorphTagVectorizer & 0.85 & 0.83 & RandomForest \\\\\n",
      "\t\tFullMorphTagVectorizer & 0.80 & 0.78 & RandomForest \\\\\n",
      "\t\tBigramMorphTagVectorizer370 & 0.77 & 0.75 & MLP \\\\\n",
      "\t\tBigramMorphTagVectorizer100 & 0.77 & 0.74 & MLP \\\\\n",
      "\t\tDPEBPVectorizer100Avg & 0.66 & 0.65 & MLP \\\\\n",
      "\t\t\\hline\n",
      "\t\\end{tabular}\n",
      "\t\\caption{Accuracy i miara F1 dla różnych sposobów wektoryzacji powieści Prusa i Sienkiewicza}\n",
      "\t\\label{tab:prus_vs_sien:vectorizer_comparison}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "prus_vs_sienkiewicz = results_df[results_df['dataset'] == 'PrusVsSienkiewicz']\n",
    "data = prus_vs_sienkiewicz.loc[prus_vs_sienkiewicz.groupby('vectorizer')['accuracy'].idxmax()]\n",
    "data = data[['vectorizer', 'accuracy', 'f1_score', 'base_head_model']].sort_values('f1_score', ascending=False)\n",
    "print(to_latex_table(\n",
    "    data,\n",
    "    place_modifiers='H',\n",
    "    separate_header=True,\n",
    "    column_names=['vectorizer', 'accuracy', 'f1 score', 'base head model'],\n",
    "    float_precission=2,\n",
    "    caption='Accuracy i miara F1 dla różnych sposobów wektoryzacji powieści Prusa i Sienkiewicza',\n",
    "    label='prus_vs_sien:vectorizer_comparison',\n",
    "    bold_labels=['f1_score', 'accuracy']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "\\begin{table}[H]\n",
      "\t\\centering\n",
      "\t\\begin{tabular}{||c|c|c|c||}\n",
      "\t\t\\hline\n",
      "\t\tvectorizer & accuracy & f1 score & base head model \\\\\n",
      "\t\t\\hline\\hline\n",
      "\t\t\\hline\n",
      "\t\\end{tabular}\n",
      "\t\\caption{Accuracy i miara F1 dla różnych sposobów wektoryzacji artykułów z gazet}\n",
      "\t\\label{tab:old_newspapers:vectorizer_comparison}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "df = results_df[results_df['dataset'] == 'OldNewspapers']\n",
    "data = df.loc[df.groupby('vectorizer')['accuracy'].idxmax()]\n",
    "data = data[['vectorizer', 'accuracy', 'f1_score', 'base_head_model']].sort_values('f1_score', ascending=False)\n",
    "print(to_latex_table(\n",
    "    data,\n",
    "    place_modifiers='H',\n",
    "    separate_header=True,\n",
    "    column_names=['vectorizer', 'accuracy', 'f1 score', 'base head model'],\n",
    "    float_precission=2,\n",
    "    caption='Accuracy i miara F1 dla różnych sposobów wektoryzacji artykułów z gazet',\n",
    "    label='old_newspapers:vectorizer_comparison',\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\t\\centering\n",
      "\t\\begin{tabular}{||c|c|c|c|c||}\n",
      "\t\t\\hline\n",
      "\t\tvectorizer & dataset & accuracy & f1 score & base head model \\\\\n",
      "\t\t\\hline\\hline\n",
      "\t\tTfidfVectorizer5000 & StarWarsFanfic & 1.00 & 1.00 & MLP \\\\\n",
      "\t\tTfidfVectorizer1000 & Classics5Authors35Books & 0.93 & 0.91 & MLP \\\\\n",
      "\t\tCountVectorizer5000 & PrusVsSienkiewicz & 0.86 & 0.84 & RandomForest \\\\\n",
      "\t\tTfidfVectorizer5000 & WritingStyle & 0.72 & 0.69 & RandomForest \\\\\n",
      "\t\tFullMorphTagVectorizer & TwitterCyberbullying & 0.93 & 0.67 & MLP \\\\\n",
      "\t\tCountVectorizer5000 & EroticVsOthers & 0.66 & 0.66 & RandomForest \\\\\n",
      "\t\tHerbertVectorizer & OldNewspapers & 0.40 & 0.24 & MLP \\\\\n",
      "\t\t\\hline\n",
      "\t\\end{tabular}\n",
      "\t\\caption{Najlepsze wektoryzery dla każdego ze zbioru danych (zwględem accuracy)}\n",
      "\t\\label{tab:best_vectorizer:classification}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "df = results_df\n",
    "data = df.loc[df.groupby('dataset')['accuracy'].idxmax()]\n",
    "data = data[['vectorizer', 'dataset', 'accuracy', 'f1_score', 'base_head_model']].sort_values('f1_score', ascending=False)\n",
    "print(to_latex_table(\n",
    "    data,\n",
    "    place_modifiers='H',\n",
    "    separate_header=True,\n",
    "    column_names=['vectorizer', 'dataset', 'accuracy', 'f1 score', 'base head model'],\n",
    "    float_precission=2,\n",
    "    caption='Najlepsze wektoryzery dla każdego ze zbioru danych (zwględem accuracy)',\n",
    "    label='best_vectorizer:classification',\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
