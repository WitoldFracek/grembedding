{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "if '..' not in sys.path:\n",
    "    sys.path.append('..')\n",
    "from notebooks.results import load_results, classification, clusterization, to_latex_table\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_letters(s: str) -> str:\n",
    "    return re.findall(r'[a-zA-Z]+', s)[0]\n",
    "\n",
    "def fix_dataset_name(s: str) -> str:\n",
    "    return {\n",
    "        'TweeterCyberbullying': 'TwitterCyberbullying'\n",
    "    }.get(s, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>datacleaner</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>params_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>silhouette</th>\n",
       "      <th>davies_bouldin</th>\n",
       "      <th>calinski_harabasz</th>\n",
       "      <th>bcubed_precission</th>\n",
       "      <th>bcubed_recall</th>\n",
       "      <th>bcubed_f1</th>\n",
       "      <th>base_head_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TwitterCyberbullying</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>MLP2</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>0.477922</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.457711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TwitterCyberbullying</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>MLP1</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>0.477922</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.457711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TwitterCyberbullying</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>MLP3</td>\n",
       "      <td>0.917413</td>\n",
       "      <td>0.541487</td>\n",
       "      <td>0.53312</td>\n",
       "      <td>0.760302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TwitterCyberbullying</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>RandomForest1</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>0.477922</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.457711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TwitterCyberbullying</td>\n",
       "      <td>DummyDatacleaner</td>\n",
       "      <td>SpacyMorphTagVectorizer</td>\n",
       "      <td>DBSCAN1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.213195</td>\n",
       "      <td>2.498378</td>\n",
       "      <td>56.53377</td>\n",
       "      <td>0.844912</td>\n",
       "      <td>0.928915</td>\n",
       "      <td>0.884924</td>\n",
       "      <td>DBSCAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                dataset       datacleaner               vectorizer  \\\n",
       "0  TwitterCyberbullying  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "1  TwitterCyberbullying  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "2  TwitterCyberbullying  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "3  TwitterCyberbullying  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "4  TwitterCyberbullying  DummyDatacleaner  SpacyMorphTagVectorizer   \n",
       "\n",
       "     params_name  accuracy  f1_score   recall  precision  silhouette  \\\n",
       "0           MLP2  0.915423  0.477922  0.50000   0.457711         NaN   \n",
       "1           MLP1  0.915423  0.477922  0.50000   0.457711         NaN   \n",
       "2           MLP3  0.917413  0.541487  0.53312   0.760302         NaN   \n",
       "3  RandomForest1  0.915423  0.477922  0.50000   0.457711         NaN   \n",
       "4        DBSCAN1       NaN       NaN      NaN        NaN    0.213195   \n",
       "\n",
       "   davies_bouldin  calinski_harabasz  bcubed_precission  bcubed_recall  \\\n",
       "0             NaN                NaN                NaN            NaN   \n",
       "1             NaN                NaN                NaN            NaN   \n",
       "2             NaN                NaN                NaN            NaN   \n",
       "3             NaN                NaN                NaN            NaN   \n",
       "4        2.498378           56.53377           0.844912       0.928915   \n",
       "\n",
       "   bcubed_f1 base_head_model  \n",
       "0        NaN             MLP  \n",
       "1        NaN             MLP  \n",
       "2        NaN             MLP  \n",
       "3        NaN    RandomForest  \n",
       "4   0.884924          DBSCAN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = load_results('../results')\n",
    "results_df['dataset'] = results_df['dataset'].apply(fix_dataset_name)\n",
    "results_df['base_head_model'] = results_df['params_name'].apply(extract_letters)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1_score': 'nan'}\n",
      "\\begin{table}[H]\n",
      "\t\\centering\n",
      "\t\\begin{tabular}{||c|c|c|c||}\n",
      "\t\t\\hline\n",
      "\t\tvectorizer & accuracy & f1 score & base head model \\\\\n",
      "\t\t\\hline\\hline\n",
      "\t\t\\hline\n",
      "\t\\end{tabular}\n",
      "\t\\caption{Accuracy i miara F1 dla różnych sposobów wektoryzacji powieści Prusa i Sienkiewicza}\n",
      "\t\\label{tab:prus_vs_sien:vectorizer_comparison}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "prus_vs_sienkiewicz = results_df[results_df['dataset'] == 'PrusVsSienkiewicz']\n",
    "data = prus_vs_sienkiewicz.loc[prus_vs_sienkiewicz.groupby('vectorizer')['accuracy'].idxmax()]\n",
    "data = data[['vectorizer', 'accuracy', 'f1_score', 'base_head_model']].sort_values('f1_score', ascending=False)\n",
    "print(to_latex_table(\n",
    "    data,\n",
    "    place_modifiers='H',\n",
    "    separate_header=True,\n",
    "    column_names=['vectorizer', 'accuracy', 'f1 score', 'base head model'],\n",
    "    float_precission=2,\n",
    "    caption='Accuracy i miara F1 dla różnych sposobów wektoryzacji powieści Prusa i Sienkiewicza',\n",
    "    label='prus_vs_sien:vectorizer_comparison',\n",
    "    bold_labels=['f1_score']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: f1_score, dtype: float64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prus_vs_sienkiewicz['f1_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "\\begin{table}[H]\n",
      "\t\\centering\n",
      "\t\\begin{tabular}{||c|c|c|c||}\n",
      "\t\t\\hline\n",
      "\t\tvectorizer & accuracy & f1 score & base head model \\\\\n",
      "\t\t\\hline\\hline\n",
      "\t\t\\hline\n",
      "\t\\end{tabular}\n",
      "\t\\caption{Accuracy i miara F1 dla różnych sposobów wektoryzacji artykułów z gazet}\n",
      "\t\\label{tab:old_newspapers:vectorizer_comparison}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "df = results_df[results_df['dataset'] == 'OldNewspapers']\n",
    "data = df.loc[df.groupby('vectorizer')['accuracy'].idxmax()]\n",
    "data = data[['vectorizer', 'accuracy', 'f1_score', 'base_head_model']].sort_values('f1_score', ascending=False)\n",
    "print(to_latex_table(\n",
    "    data,\n",
    "    place_modifiers='H',\n",
    "    separate_header=True,\n",
    "    column_names=['vectorizer', 'accuracy', 'f1 score', 'base head model'],\n",
    "    float_precission=2,\n",
    "    caption='Accuracy i miara F1 dla różnych sposobów wektoryzacji artykułów z gazet',\n",
    "    label='old_newspapers:vectorizer_comparison',\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "\t\\centering\n",
      "\t\\begin{tabular}{||c|c|c|c|c||}\n",
      "\t\t\\hline\n",
      "\t\tvectorizer & dataset & accuracy & f1 score & base head model \\\\\n",
      "\t\t\\hline\\hline\n",
      "\t\tTfidfVectorizer5000 & StarWarsFanfic & 1.00 & 1.00 & MLP \\\\\n",
      "\t\tTfidfVectorizer1000 & Classics5Authors35Books & 0.93 & 0.91 & MLP \\\\\n",
      "\t\tCountVectorizer5000 & PrusVsSienkiewicz & 0.86 & 0.84 & RandomForest \\\\\n",
      "\t\tTfidfVectorizer5000 & WritingStyle & 0.72 & 0.69 & RandomForest \\\\\n",
      "\t\tFullMorphTagVectorizer & TwitterCyberbullying & 0.93 & 0.67 & MLP \\\\\n",
      "\t\tCountVectorizer5000 & EroticVsOthers & 0.66 & 0.66 & RandomForest \\\\\n",
      "\t\tHerbertVectorizer & OldNewspapers & 0.40 & 0.24 & MLP \\\\\n",
      "\t\t\\hline\n",
      "\t\\end{tabular}\n",
      "\t\\caption{Najlepsze wektoryzery dla każdego ze zbioru danych (zwględem accuracy)}\n",
      "\t\\label{tab:best_vectorizer:classification}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "df = results_df\n",
    "data = df.loc[df.groupby('dataset')['accuracy'].idxmax()]\n",
    "data = data[['vectorizer', 'dataset', 'accuracy', 'f1_score', 'base_head_model']].sort_values('f1_score', ascending=False)\n",
    "print(to_latex_table(\n",
    "    data,\n",
    "    place_modifiers='H',\n",
    "    separate_header=True,\n",
    "    column_names=['vectorizer', 'dataset', 'accuracy', 'f1 score', 'base head model'],\n",
    "    float_precission=2,\n",
    "    caption='Najlepsze wektoryzery dla każdego ze zbioru danych (zwględem accuracy)',\n",
    "    label='best_vectorizer:classification',\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
