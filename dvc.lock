schema: '2.0'
stages:
  load@0:
    cmd:
    - echo data/TweeterCyberbullying/raw/test.parquet
    - python scripts/load.py "TweeterCyberbullying"
    deps:
    - path: datasets_raw/
      hash: md5
      md5: d4d63909bc037c523a8b928d3d78ff21.dir
      size: 170828345
      nfiles: 665
    - path: imports_validator/load/TweeterCyberbullying.yaml
      hash: md5
      md5: 1194a03650ece56561c7d32422108dad
      size: 105
    - path: scripts/load.py
      hash: md5
      md5: 9512de4cace625fee622ef910c4b2a9b
      size: 810
    - path: stages/dataloaders/TweeterCyberbullying.py
      hash: md5
      md5: 3741825fb5be6c439d74adcec5f2a096
      size: 586
    outs:
    - path: data/TweeterCyberbullying/raw
      hash: md5
      md5: e4bd411a2f7812d9f1afc1ecf9a33dd2.dir
      size: 446957
      nfiles: 2
  load@1:
    cmd:
    - echo data/PrusVsSienkiewicz/raw/test.parquet
    - python scripts/load.py "PrusVsSienkiewicz"
    deps:
    - path: datasets_raw/
      hash: md5
      md5: d4d63909bc037c523a8b928d3d78ff21.dir
      size: 170828345
      nfiles: 665
    - path: imports_validator/load/PrusVsSienkiewicz.yaml
      hash: md5
      md5: 1194a03650ece56561c7d32422108dad
      size: 105
    - path: scripts/load.py
      hash: md5
      md5: 9512de4cace625fee622ef910c4b2a9b
      size: 810
    - path: stages/dataloaders/PrusVsSienkiewicz.py
      hash: md5
      md5: 83efa035a99f81ee450cd920934d2546
      size: 4071
    outs:
    - path: data/PrusVsSienkiewicz/raw
      hash: md5
      md5: b67a0a1a68556164f58a97132a2e90cd.dir
      size: 2944855
      nfiles: 2
  clean@0:
    cmd:
    - python scripts/clean.py "TweeterCyberbullying" "DummyDatacleaner"
    deps:
    - path: data/TweeterCyberbullying/raw
      hash: md5
      md5: e4bd411a2f7812d9f1afc1ecf9a33dd2.dir
      size: 446957
      nfiles: 2
    - path: imports_validator/clean/DummyDatacleaner.yaml
      hash: md5
      md5: f9fb26f31e9ee4ef1773b063a73087f8
      size: 70
    - path: scripts/clean.py
      hash: md5
      md5: 8f3ab3ce5cbd679d18c72367fe31bdcf
      size: 812
    - path: stages/datacleaners/DummyDatacleaner.py
      hash: md5
      md5: 312a109a16cbfa0a27fa40214d7f18d0
      size: 414
    outs:
    - path: data/TweeterCyberbullying/DummyDatacleaner
      hash: md5
      md5: 0e749897e23b2e631bc8c162f54a8b86.dir
      size: 447065
      nfiles: 2
  vectorize@0:
    cmd: python scripts/vectorize.py "WritingStyle" "DummyDatacleaner" "CountVectorizer1000"
    deps:
    - path: data/WritingStyle/DummyDatacleaner
      hash: md5
      md5: 5ab6a07aebeaf54e356a0e762c4eb7aa.dir
      size: 8178295
      nfiles: 2
    - path: imports_validator/vectorize/CountVectorizer1000.yaml
      hash: md5
      md5: 1d7228b3d4f526b074d92f9975daf866
      size: 105
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/CountVectorizer1000.py
      hash: md5
      md5: 387f11db76a6ff0c388c63b9310b6387
      size: 176
    outs:
    - path: data/WritingStyle/DummyDatacleaner_CountVectorizer1000
      hash: md5
      md5: b7cccd92c364753e0d4cfdfbeb1b591a.dir
      size: 1567069
      nfiles: 1
  evaluate@data0-model0:
    cmd: python scripts/evaluate.py "RpTweetsXS" "LemmatizerSM" "CountVectorizer1000"
      "SVC" "SVC1"
    deps:
    - path: data/RpTweetsXS/LemmatizerSM_CountVectorizer1000
      hash: md5
      md5: fa48c5b02d06f01894ce7ccf38d9431a.dir
      size: 718452
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC1.yaml
      hash: md5
      md5: 4d4566ceb63190a6b78049a19328cb4c
      size: 5
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: mlruns_store/RpTweetsXS/LemmatizerSM/CountVectorizer1000/SVC/SVC1
      hash: md5
      md5: 2b6d43f21250700ec78f74afef910242.dir
      size: 851379
      nfiles: 47
    - path: results/RpTweetsXS/LemmatizerSM/CountVectorizer1000/SVC/SVC1.json
      hash: md5
      md5: 9ea3a412b3bda8ed5c5c9967c68fb6dc
      size: 166
  evaluate@data0-model1:
    cmd: python scripts/evaluate.py "RpTweetsXS" "LemmatizerSM" "CountVectorizer1000"
      "SVC" "SVC2"
    deps:
    - path: data/RpTweetsXS/LemmatizerSM_CountVectorizer1000
      hash: md5
      md5: fa48c5b02d06f01894ce7ccf38d9431a.dir
      size: 718452
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC2.yaml
      hash: md5
      md5: dcc2e18360f768734743656c9a4ef885
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: mlruns_store/RpTweetsXS/LemmatizerSM/CountVectorizer1000/SVC/SVC2
      hash: md5
      md5: 0432ea5bb0038eadf7f582d382e60fd3.dir
      size: 852690
      nfiles: 47
    - path: results/RpTweetsXS/LemmatizerSM/CountVectorizer1000/SVC/SVC2.json
      hash: md5
      md5: 15a77ca4809668e766f0c6d6ed253638
      size: 166
  clean@1:
    cmd:
    - python scripts/clean.py "PrusVsSienkiewicz" "DummyDatacleaner"
    deps:
    - path: data/PrusVsSienkiewicz/raw
      hash: md5
      md5: b67a0a1a68556164f58a97132a2e90cd.dir
      size: 2944855
      nfiles: 2
    - path: imports_validator/clean/DummyDatacleaner.yaml
      hash: md5
      md5: f9fb26f31e9ee4ef1773b063a73087f8
      size: 70
    - path: scripts/clean.py
      hash: md5
      md5: 8f3ab3ce5cbd679d18c72367fe31bdcf
      size: 812
    - path: stages/datacleaners/DummyDatacleaner.py
      hash: md5
      md5: 312a109a16cbfa0a27fa40214d7f18d0
      size: 414
    outs:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner
      hash: md5
      md5: 158cfdabbc59e3e69e52252586c898c6.dir
      size: 2944961
      nfiles: 2
  vectorize@1:
    cmd: python scripts/vectorize.py "WritingStyle" "DummyDatacleaner" "CountVectorizer5000"
    deps:
    - path: data/WritingStyle/DummyDatacleaner
      hash: md5
      md5: 5ab6a07aebeaf54e356a0e762c4eb7aa.dir
      size: 8178295
      nfiles: 2
    - path: imports_validator/vectorize/CountVectorizer5000.yaml
      hash: md5
      md5: 1d7228b3d4f526b074d92f9975daf866
      size: 105
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/CountVectorizer5000.py
      hash: md5
      md5: caa23a258bbb68acc496765ee07836d2
      size: 176
    outs:
    - path: data/WritingStyle/DummyDatacleaner_CountVectorizer5000
      hash: md5
      md5: d01e692423534333f4c5a9ea7dc888a1.dir
      size: 3293511
      nfiles: 1
  evaluate@data1-model0:
    cmd: python scripts/evaluate.py "RpTweetsXS" "TweetNormalization" "CountVectorizer1000"
      "SVC" "SVC1"
    deps:
    - path: data/RpTweetsXS/TweetNormalization_CountVectorizer1000
      hash: md5
      md5: 9ed3d49f1387658f33cee54f025fd443.dir
      size: 867686
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC1.yaml
      hash: md5
      md5: 4d4566ceb63190a6b78049a19328cb4c
      size: 5
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: mlruns_store/RpTweetsXS/TweetNormalization/CountVectorizer1000/SVC/SVC1
      hash: md5
      md5: 76745958cd65220833d7bf02b56902b4.dir
      size: 850327
      nfiles: 47
    - path: results/RpTweetsXS/TweetNormalization/CountVectorizer1000/SVC/SVC1.json
      hash: md5
      md5: fcb2fbcb31882b5d0c94a1944c55c95a
      size: 173
  vectorize@2:
    cmd: python scripts/vectorize.py "WritingStyle" "DummyDatacleaner" "TfidfVectorizer1000"
    deps:
    - path: data/WritingStyle/DummyDatacleaner
      hash: md5
      md5: 5ab6a07aebeaf54e356a0e762c4eb7aa.dir
      size: 8178295
      nfiles: 2
    - path: imports_validator/vectorize/TfidfVectorizer1000.yaml
      hash: md5
      md5: 4b0fb66e4cd38e48297c69d9c3d4a73f
      size: 105
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/TfidfVectorizer1000.py
      hash: md5
      md5: b11ea89cd9a64b1ad574f32764f0e1b8
      size: 241
    outs:
    - path: data/WritingStyle/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: 37f2f084cb60c8096d9987a437728788.dir
      size: 7341646
      nfiles: 1
  vectorize@3:
    cmd: python scripts/vectorize.py "WritingStyle" "DummyDatacleaner" "TfidfVectorizer5000"
    deps:
    - path: data/WritingStyle/DummyDatacleaner
      hash: md5
      md5: 5ab6a07aebeaf54e356a0e762c4eb7aa.dir
      size: 8178295
      nfiles: 2
    - path: imports_validator/vectorize/TfidfVectorizer5000.yaml
      hash: md5
      md5: 4b0fb66e4cd38e48297c69d9c3d4a73f
      size: 105
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/TfidfVectorizer5000.py
      hash: md5
      md5: 7fa98b1029c28853802942a4622186e6
      size: 241
    outs:
    - path: data/WritingStyle/DummyDatacleaner_TfidfVectorizer5000
      hash: md5
      md5: 3799bc8deb06cc3f5dedbb007eca2905.dir
      size: 11710062
      nfiles: 1
  evaluate@data2-model0:
    cmd: python scripts/evaluate.py "RpTweetsXS" "LemmatizerSM" "CountVectorizer5000"
      "SVC" "SVC1"
    deps:
    - path: data/RpTweetsXS/LemmatizerSM_CountVectorizer5000
      hash: md5
      md5: 687dc9ab93f104cd997bbfb98f46daeb.dir
      size: 1859564
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC1.yaml
      hash: md5
      md5: 4d4566ceb63190a6b78049a19328cb4c
      size: 5
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: mlruns_store/RpTweetsXS/LemmatizerSM/CountVectorizer5000/SVC/SVC1
      hash: md5
      md5: 70ccd95732af9c30d019957ddebdd8e7.dir
      size: 4050956
      nfiles: 47
    - path: results/RpTweetsXS/LemmatizerSM/CountVectorizer5000/SVC/SVC1.json
      hash: md5
      md5: 32ef9223eaed9dd0e89857138d220918
      size: 167
  evaluate@data3-model0:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer1000"
      "SVC" "SVC1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer1000
      hash: md5
      md5: aae95d50927870dcaaa11ca2ebb6cf7e.dir
      size: 3267474
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC1.yaml
      hash: md5
      md5: 4d4566ceb63190a6b78049a19328cb4c
      size: 5
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer1000/SVC/SVC1
      hash: md5
      md5: da6944a1de40ca5f851bb153231578d4.dir
      size: 847718
      nfiles: 47
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer1000/SVC/SVC1.json
      hash: md5
      md5: 8e539ea9743c6c25caf3b1fcff2d2fc4
      size: 184
  vectorize@4:
    cmd: python scripts/vectorize.py "WritingStyle" "DummyDatacleaner" "BigramMorphTagVectorizer100"
    deps:
    - path: data/WritingStyle/DummyDatacleaner
      hash: md5
      md5: 5ab6a07aebeaf54e356a0e762c4eb7aa.dir
      size: 8178295
      nfiles: 2
    - path: imports_validator/vectorize/BigramMorphTagVectorizer100.yaml
      hash: md5
      md5: bc55fa25823ad9fef3760873f765423c
      size: 105
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/BigramMorphTagVectorizer100.py
      hash: md5
      md5: cfd32d2370fced3303f0ec87ea5e096f
      size: 210
    outs:
    - path: data/WritingStyle/DummyDatacleaner_BigramMorphTagVectorizer100
      hash: md5
      md5: f439d91af2a373de91f144c1faba296d.dir
      size: 7479969
      nfiles: 1
  vectorize@5:
    cmd: python scripts/vectorize.py "WritingStyle" "DummyDatacleaner" "BigramMorphTagVectorizer370"
    deps:
    - path: data/WritingStyle/DummyDatacleaner
      hash: md5
      md5: 5ab6a07aebeaf54e356a0e762c4eb7aa.dir
      size: 8178295
      nfiles: 2
    - path: imports_validator/vectorize/BigramMorphTagVectorizer370.yaml
      hash: md5
      md5: bc55fa25823ad9fef3760873f765423c
      size: 105
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/BigramMorphTagVectorizer370.py
      hash: md5
      md5: 16f16b280929fd0623d74e9e0ceaa90f
      size: 210
    outs:
    - path: data/WritingStyle/DummyDatacleaner_BigramMorphTagVectorizer370
      hash: md5
      md5: 148881352428f8e7adee21ba13f37c3e.dir
      size: 27675617
      nfiles: 1
  vectorize@6:
    cmd: python scripts/vectorize.py "WritingStyle" "DummyDatacleaner" "DPEBPVectorizer100Avg"
    deps:
    - path: data/WritingStyle/DummyDatacleaner
      hash: md5
      md5: 5ab6a07aebeaf54e356a0e762c4eb7aa.dir
      size: 8178295
      nfiles: 2
    - path: imports_validator/vectorize/DPEBPVectorizer100Avg.yaml
      hash: md5
      md5: 7a36e54f419c412304594fd35c32a380
      size: 140
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/DPEBPVectorizer100Avg.py
      hash: md5
      md5: 2fc43803ca207c200729f7e9d1994a15
      size: 198
    outs:
    - path: data/WritingStyle/DummyDatacleaner_DPEBPVectorizer100Avg
      hash: md5
      md5: bd5575da392b5d72cb810f0bb282478b.dir
      size: 3621783
      nfiles: 1
  vectorize@7:
    cmd: python scripts/vectorize.py "WritingStyle" "DummyDatacleaner" "FullMorphTagVectorizer"
    deps:
    - path: data/WritingStyle/DummyDatacleaner
      hash: md5
      md5: 5ab6a07aebeaf54e356a0e762c4eb7aa.dir
      size: 8178295
      nfiles: 2
    - path: imports_validator/vectorize/FullMorphTagVectorizer.yaml
      hash: md5
      md5: 1a5da03c53448225d41c4aaa582cb7ee
      size: 70
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/FullMorphTagVectorizer.py
      hash: md5
      md5: 54e597d41d11ec1937294a717cec71c9
      size: 2460
    outs:
    - path: data/WritingStyle/DummyDatacleaner_FullMorphTagVectorizer
      hash: md5
      md5: 9ea3b495a26cc6e9a6814e5f2dfaf5de.dir
      size: 3281342
      nfiles: 1
  evaluate@data4-model0:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer5000"
      "SVC" "SVC1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer5000
      hash: md5
      md5: 4b866208d010ae338c9a3365c4a3931c.dir
      size: 7565280
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC1.yaml
      hash: md5
      md5: 4d4566ceb63190a6b78049a19328cb4c
      size: 5
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer5000/SVC/SVC1
      hash: md5
      md5: 0dbdd6e4aaa0e5c8ea5d55aba9173777.dir
      size: 4046934
      nfiles: 47
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer5000/SVC/SVC1.json
      hash: md5
      md5: c8f9c766ee1e817cc42792d8c7ed3fb0
      size: 184
  evaluate@data5-model0:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer1000"
      "SVC" "SVC1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer1000
      hash: md5
      md5: de24f4fb97320115fd15b7d79dfb0ef4.dir
      size: 10489890
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC1.yaml
      hash: md5
      md5: 4d4566ceb63190a6b78049a19328cb4c
      size: 5
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer1000/SVC/SVC1
      hash: md5
      md5: 81b2ce28cf40bf8fbc2e186f0f9e2d54.dir
      size: 847656
      nfiles: 47
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer1000/SVC/SVC1.json
      hash: md5
      md5: c86bcfffaf55f3b2160813158bafb5a5
      size: 184
  evaluate@data6-model0:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer5000"
      "SVC" "SVC1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer5000
      hash: md5
      md5: 397b9e47e1cbca601658f751b4b96840.dir
      size: 18137919
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC1.yaml
      hash: md5
      md5: 4d4566ceb63190a6b78049a19328cb4c
      size: 5
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer5000/SVC/SVC1
      hash: md5
      md5: eb2e80bee73b2300dfd04a6dfeff7a93.dir
      size: 4048036
      nfiles: 47
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer5000/SVC/SVC1.json
      hash: md5
      md5: 683843a610f9155e857106b4a984f5d8
      size: 184
  evaluate@data7-model0:
    cmd: python scripts/evaluate.py "RpTweetsXS" "TweetNormalization" "TfidfVectorizer5000"
      "SVC" "SVC3"
    deps:
    - path: data/RpTweetsXS/TweetNormalization_TfidfVectorizer5000
      hash: md5
      md5: ec59dcd0b1cc366c46eb199ba75082da.dir
      size: 1071534776
      nfiles: 4
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    - path: stages/models/SVC.py
      hash: md5
      md5: 83effad05bcb21943fb1429553d87d76
      size: 1713
    outs:
    - path: results/RpTweetsXS_TweetNormalization_TfidfVectorizer5000_SVC_SVC3.json
      hash: md5
      md5: 5d53074f3b25a47e69087e48dafe3d62
      size: 173
  evaluate@data1-model1:
    cmd: python scripts/evaluate.py "RpTweetsXS" "TweetNormalization" "CountVectorizer1000"
      "SVC" "SVC2"
    deps:
    - path: data/RpTweetsXS/TweetNormalization_CountVectorizer1000
      hash: md5
      md5: 9ed3d49f1387658f33cee54f025fd443.dir
      size: 867686
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC2.yaml
      hash: md5
      md5: dcc2e18360f768734743656c9a4ef885
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: mlruns_store/RpTweetsXS/TweetNormalization/CountVectorizer1000/SVC/SVC2
      hash: md5
      md5: cfb00d6006e23e324da2217e0a7a01ce.dir
      size: 851838
      nfiles: 47
    - path: results/RpTweetsXS/TweetNormalization/CountVectorizer1000/SVC/SVC2.json
      hash: md5
      md5: f0dc6cc4980aeeb3dae3fa0f4cff265f
      size: 173
  evaluate@data2-model1:
    cmd: python scripts/evaluate.py "RpTweetsXS" "LemmatizerSM" "CountVectorizer5000"
      "SVC" "SVC2"
    deps:
    - path: data/RpTweetsXS/LemmatizerSM_CountVectorizer5000
      hash: md5
      md5: 687dc9ab93f104cd997bbfb98f46daeb.dir
      size: 1859564
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC2.yaml
      hash: md5
      md5: dcc2e18360f768734743656c9a4ef885
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: mlruns_store/RpTweetsXS/LemmatizerSM/CountVectorizer5000/SVC/SVC2
      hash: md5
      md5: a6048f9728aaef38d2cfb7b1959be069.dir
      size: 4052961
      nfiles: 47
    - path: results/RpTweetsXS/LemmatizerSM/CountVectorizer5000/SVC/SVC2.json
      hash: md5
      md5: c0d99d49a14ee7ee8893c7e1355dd76a
      size: 167
  evaluate@data3-model1:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer1000"
      "SVC" "SVC2"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer1000
      hash: md5
      md5: aae95d50927870dcaaa11ca2ebb6cf7e.dir
      size: 3267474
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC2.yaml
      hash: md5
      md5: dcc2e18360f768734743656c9a4ef885
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer1000/SVC/SVC2
      hash: md5
      md5: 567a14c55544bebdac528a181d8035fe.dir
      size: 848639
      nfiles: 47
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer1000/SVC/SVC2.json
      hash: md5
      md5: c98a5134cb5dfdfaea8d02ba9037ddb7
      size: 184
  evaluate@data4-model1:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer5000"
      "SVC" "SVC2"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer5000
      hash: md5
      md5: 4b866208d010ae338c9a3365c4a3931c.dir
      size: 7565280
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC2.yaml
      hash: md5
      md5: dcc2e18360f768734743656c9a4ef885
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer5000/SVC/SVC2
      hash: md5
      md5: 1a8a6bf5ee5498c948aeb3e24efa0172.dir
      size: 4048145
      nfiles: 47
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer5000/SVC/SVC2.json
      hash: md5
      md5: d058bf81358f71e810c35ceb75b7ffbd
      size: 184
  evaluate@data5-model1:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer1000"
      "SVC" "SVC2"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer1000
      hash: md5
      md5: de24f4fb97320115fd15b7d79dfb0ef4.dir
      size: 10489890
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC2.yaml
      hash: md5
      md5: dcc2e18360f768734743656c9a4ef885
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer1000/SVC/SVC2
      hash: md5
      md5: 553200658fd07e163f50fa784a0917f5.dir
      size: 842398
      nfiles: 47
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer1000/SVC/SVC2.json
      hash: md5
      md5: 09d433d45f3a4f4088fde4d2ce7b8be5
      size: 184
  evaluate@data6-model1:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer5000"
      "SVC" "SVC2"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer5000
      hash: md5
      md5: 397b9e47e1cbca601658f751b4b96840.dir
      size: 18137919
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC2.yaml
      hash: md5
      md5: dcc2e18360f768734743656c9a4ef885
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer5000/SVC/SVC2
      hash: md5
      md5: f18c1ef9a4843976360b3450f40a49c5.dir
      size: 4042402
      nfiles: 47
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer5000/SVC/SVC2.json
      hash: md5
      md5: abd6565957e72132c6b80582030ecbc6
      size: 184
  evaluate@data7-model1:
    cmd: python scripts/evaluate.py "RpTweetsXS" "TweetNormalization" "TfidfVectorizer5000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/RpTweetsXS/TweetNormalization_TfidfVectorizer5000
      hash: md5
      md5: ec59dcd0b1cc366c46eb199ba75082da.dir
      size: 1071534776
      nfiles: 4
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 95623765423b8a1e454d0874b59abbb1
      size: 3746
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: 
        results/RpTweetsXS_TweetNormalization_TfidfVectorizer5000_LogisticRegression_LR1.json
      hash: md5
      md5: f26b78126ebbdd7ce23058b4cbe62c08
      size: 353
  load@2:
    cmd:
    - echo data/WritingStyle/raw/test.parquet
    - python scripts/load.py "WritingStyle"
    deps:
    - path: datasets_raw/
      hash: md5
      md5: d4d63909bc037c523a8b928d3d78ff21.dir
      size: 170828345
      nfiles: 665
    - path: imports_validator/load/WritingStyle.yaml
      hash: md5
      md5: bf788a22204ae05588c72d2b35c51afd
      size: 70
    - path: scripts/load.py
      hash: md5
      md5: 9512de4cace625fee622ef910c4b2a9b
      size: 810
    - path: stages/dataloaders/WritingStyle.py
      hash: md5
      md5: 8b7d4fd3b4312d20330258e3b9f8ad24
      size: 2723
    outs:
    - path: data/WritingStyle/raw
      hash: md5
      md5: 3a38b97f3e68af11769ead30ddcc88b0.dir
      size: 8178187
      nfiles: 2
  clean@2:
    cmd:
    - python scripts/clean.py "WritingStyle" "DummyDatacleaner"
    deps:
    - path: data/WritingStyle/raw
      hash: md5
      md5: 3a38b97f3e68af11769ead30ddcc88b0.dir
      size: 8178187
      nfiles: 2
    - path: imports_validator/clean/DummyDatacleaner.yaml
      hash: md5
      md5: f9fb26f31e9ee4ef1773b063a73087f8
      size: 70
    - path: scripts/clean.py
      hash: md5
      md5: 8f3ab3ce5cbd679d18c72367fe31bdcf
      size: 812
    - path: stages/datacleaners/DummyDatacleaner.py
      hash: md5
      md5: 312a109a16cbfa0a27fa40214d7f18d0
      size: 414
    outs:
    - path: data/WritingStyle/DummyDatacleaner
      hash: md5
      md5: 5ab6a07aebeaf54e356a0e762c4eb7aa.dir
      size: 8178295
      nfiles: 2
  clean@3:
    cmd:
    - python scripts/clean.py "Classics5Authors35Books" "DummyDatacleaner"
    deps:
    - path: data/Classics5Authors35Books/raw
      hash: md5
      md5: dfa7ca76af85d617602d7a1c786e3e5f.dir
      size: 12349037
      nfiles: 2
    - path: imports_validator/clean/DummyDatacleaner.yaml
      hash: md5
      md5: f9fb26f31e9ee4ef1773b063a73087f8
      size: 70
    - path: scripts/clean.py
      hash: md5
      md5: 8f3ab3ce5cbd679d18c72367fe31bdcf
      size: 812
    - path: stages/datacleaners/DummyDatacleaner.py
      hash: md5
      md5: 312a109a16cbfa0a27fa40214d7f18d0
      size: 414
    outs:
    - path: data/Classics5Authors35Books/DummyDatacleaner
      hash: md5
      md5: 4a63ab08d945b568bef9adb7cd9b9e51.dir
      size: 12349137
      nfiles: 2
  clean@4:
    cmd:
    - python scripts/clean.py "MsTweets" "TweetNormalizationHashtagSkip"
    deps:
    - path: data/MsTweets/raw
      hash: md5
      md5: 69a81154bcee9535449243027593e500.dir
      size: 7470212
      nfiles: 2
    - path: scripts/clean.py
      hash: md5
      md5: a35073fb8ed6b407b4d09d0c795ba62e
      size: 842
    - path: stages/datacleaners/DataCleaner.py
      hash: md5
      md5: 934ee50d1e9610c307610a8e3a986a47
      size: 2132
    - path: stages/datacleaners/TweetNormalizationHashtagSkip.py
      hash: md5
      md5: b1fee1606ab7ac84c1b8fa62d454e28e
      size: 1789
    outs:
    - path: data/MsTweets/TweetNormalizationHashtagSkip
      hash: md5
      md5: 02a0d124655b72fb560c375177908c3a.dir
      size: 5928977
      nfiles: 2
  load@3:
    cmd:
    - echo data/Classics5Authors35Books/raw/test.parquet
    - python scripts/load.py "Classics5Authors35Books"
    deps:
    - path: datasets_raw/
      hash: md5
      md5: d4d63909bc037c523a8b928d3d78ff21.dir
      size: 170828345
      nfiles: 665
    - path: imports_validator/load/Classics5Authors35Books.yaml
      hash: md5
      md5: bf788a22204ae05588c72d2b35c51afd
      size: 70
    - path: scripts/load.py
      hash: md5
      md5: 9512de4cace625fee622ef910c4b2a9b
      size: 810
    - path: stages/dataloaders/Classics5Authors35Books.py
      hash: md5
      md5: e081cece84ab30c34f6f0b91e3ccc817
      size: 4595
    outs:
    - path: data/Classics5Authors35Books/raw
      hash: md5
      md5: dfa7ca76af85d617602d7a1c786e3e5f.dir
      size: 12349037
      nfiles: 2
  clean@5:
    cmd:
    - python scripts/clean.py "MsTweetsV2" "TweetNormalizationHashtagSkip"
    deps:
    - path: data/MsTweetsV2/raw
      hash: md5
      md5: 1f8d340b2eb91b7330bf6dbdf3f0d5fd.dir
      size: 15327311
      nfiles: 2
    - path: scripts/clean.py
      hash: md5
      md5: a35073fb8ed6b407b4d09d0c795ba62e
      size: 842
    - path: stages/datacleaners/DataCleaner.py
      hash: md5
      md5: 934ee50d1e9610c307610a8e3a986a47
      size: 2132
    - path: stages/datacleaners/TweetNormalizationHashtagSkip.py
      hash: md5
      md5: b1fee1606ab7ac84c1b8fa62d454e28e
      size: 1789
    outs:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip
      hash: md5
      md5: ad0ff1abdb0b197995b6d6a74818bfbf.dir
      size: 12959052
      nfiles: 2
  clean@6:
    cmd:
    - python scripts/clean.py "MsTweetsV2" "LemmatizerSM"
    deps:
    - path: data/MsTweetsV2/raw
      hash: md5
      md5: 1f8d340b2eb91b7330bf6dbdf3f0d5fd.dir
      size: 15327311
      nfiles: 2
    - path: scripts/clean.py
      hash: md5
      md5: a35073fb8ed6b407b4d09d0c795ba62e
      size: 842
    - path: stages/datacleaners/DataCleaner.py
      hash: md5
      md5: 934ee50d1e9610c307610a8e3a986a47
      size: 2132
    - path: stages/datacleaners/LemmatizerSM.py
      hash: md5
      md5: 03c77875fd12ea1f34c54f679c734623
      size: 1300
    outs:
    - path: data/MsTweetsV2/LemmatizerSM
      hash: md5
      md5: d43b920202fa194517988915aa67dc47.dir
      size: 12523473
      nfiles: 2
  vectorize@8:
    cmd: python scripts/vectorize.py "WritingStyle" "DummyDatacleaner" "SpacyMorphTagVectorizer"
    deps:
    - path: data/WritingStyle/DummyDatacleaner
      hash: md5
      md5: 5ab6a07aebeaf54e356a0e762c4eb7aa.dir
      size: 8178295
      nfiles: 2
    - path: imports_validator/vectorize/SpacyMorphTagVectorizer.yaml
      hash: md5
      md5: 1a5da03c53448225d41c4aaa582cb7ee
      size: 70
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/SpacyMorphTagVectorizer.py
      hash: md5
      md5: 1c494b8efa04cd654322aafe26bd093c
      size: 3511
    outs:
    - path: data/WritingStyle/DummyDatacleaner_SpacyMorphTagVectorizer
      hash: md5
      md5: ca4951116d90f6f090f6b5335896bbf0.dir
      size: 2290253
      nfiles: 1
  vectorize@9:
    cmd: python scripts/vectorize.py "Classics5Authors35Books" "DummyDatacleaner"
      "CountVectorizer1000"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner
      hash: md5
      md5: 4a63ab08d945b568bef9adb7cd9b9e51.dir
      size: 12349137
      nfiles: 2
    - path: imports_validator/vectorize/CountVectorizer1000.yaml
      hash: md5
      md5: 1d7228b3d4f526b074d92f9975daf866
      size: 105
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/CountVectorizer1000.py
      hash: md5
      md5: 387f11db76a6ff0c388c63b9310b6387
      size: 176
    outs:
    - path: data/Classics5Authors35Books/DummyDatacleaner_CountVectorizer1000
      hash: md5
      md5: 7ee049b17d3e8053b2b987280e8db14f.dir
      size: 1666638
      nfiles: 1
  vectorize@10:
    cmd: python scripts/vectorize.py "Classics5Authors35Books" "DummyDatacleaner"
      "CountVectorizer5000"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner
      hash: md5
      md5: 4a63ab08d945b568bef9adb7cd9b9e51.dir
      size: 12349137
      nfiles: 2
    - path: imports_validator/vectorize/CountVectorizer5000.yaml
      hash: md5
      md5: 1d7228b3d4f526b074d92f9975daf866
      size: 105
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/CountVectorizer5000.py
      hash: md5
      md5: caa23a258bbb68acc496765ee07836d2
      size: 176
    outs:
    - path: data/Classics5Authors35Books/DummyDatacleaner_CountVectorizer5000
      hash: md5
      md5: d3c7b1e5f2d05bbeb79193b7588ae75e.dir
      size: 3746404
      nfiles: 1
  vectorize@11:
    cmd: python scripts/vectorize.py "Classics5Authors35Books" "DummyDatacleaner"
      "TfidfVectorizer1000"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner
      hash: md5
      md5: 4a63ab08d945b568bef9adb7cd9b9e51.dir
      size: 12349137
      nfiles: 2
    - path: imports_validator/vectorize/TfidfVectorizer1000.yaml
      hash: md5
      md5: 4b0fb66e4cd38e48297c69d9c3d4a73f
      size: 105
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/TfidfVectorizer1000.py
      hash: md5
      md5: b11ea89cd9a64b1ad574f32764f0e1b8
      size: 241
    outs:
    - path: data/Classics5Authors35Books/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: 4c27a0564c9a8edeaebed9007d72edc9.dir
      size: 9156365
      nfiles: 1
  evaluate@data0-model2:
    cmd: python scripts/evaluate.py "RpTweetsXS" "LemmatizerSM" "CountVectorizer1000"
      "SVC" "SVC3"
    deps:
    - path: data/RpTweetsXS/LemmatizerSM_CountVectorizer1000
      hash: md5
      md5: fa48c5b02d06f01894ce7ccf38d9431a.dir
      size: 718452
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: mlruns_store/RpTweetsXS/LemmatizerSM/CountVectorizer1000/SVC/SVC3
      hash: md5
      md5: d09926913ead635d0d66d7813b0f6c9a.dir
      size: 852417
      nfiles: 47
    - path: results/RpTweetsXS/LemmatizerSM/CountVectorizer1000/SVC/SVC3.json
      hash: md5
      md5: 06dba9e6177ca87dce671a04cd38da23
      size: 167
  evaluate@data1-model2:
    cmd: python scripts/evaluate.py "RpTweetsXS" "TweetNormalization" "CountVectorizer1000"
      "SVC" "SVC3"
    deps:
    - path: data/RpTweetsXS/TweetNormalization_CountVectorizer1000
      hash: md5
      md5: 9ed3d49f1387658f33cee54f025fd443.dir
      size: 867686
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: mlruns_store/RpTweetsXS/TweetNormalization/CountVectorizer1000/SVC/SVC3
      hash: md5
      md5: 67c089e26b14415c2d348967109a6e58.dir
      size: 851838
      nfiles: 47
    - path: results/RpTweetsXS/TweetNormalization/CountVectorizer1000/SVC/SVC3.json
      hash: md5
      md5: eafb89b596830ab82e75b97ea03e10d5
      size: 173
  evaluate@data2-model2:
    cmd: python scripts/evaluate.py "RpTweetsXS" "LemmatizerSM" "CountVectorizer5000"
      "SVC" "SVC3"
    deps:
    - path: data/RpTweetsXS/LemmatizerSM_CountVectorizer5000
      hash: md5
      md5: 687dc9ab93f104cd997bbfb98f46daeb.dir
      size: 1859564
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: mlruns_store/RpTweetsXS/LemmatizerSM/CountVectorizer5000/SVC/SVC3
      hash: md5
      md5: 51cee2661296069213df2f2194431002.dir
      size: 4053058
      nfiles: 47
    - path: results/RpTweetsXS/LemmatizerSM/CountVectorizer5000/SVC/SVC3.json
      hash: md5
      md5: 3026d942642cb3c2d3c8a8b1a8705b1f
      size: 167
  evaluate@data3-model2:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer1000"
      "SVC" "SVC3"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer1000
      hash: md5
      md5: aae95d50927870dcaaa11ca2ebb6cf7e.dir
      size: 3267474
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer1000/SVC/SVC3
      hash: md5
      md5: f9d75e2e3ac32b327710ec3d1e1b199b.dir
      size: 849391
      nfiles: 47
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer1000/SVC/SVC3.json
      hash: md5
      md5: 96c56bf9f12b318948598960e6eb563a
      size: 184
  evaluate@data4-model2:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer5000"
      "SVC" "SVC3"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer5000
      hash: md5
      md5: 4b866208d010ae338c9a3365c4a3931c.dir
      size: 7565280
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer5000/SVC/SVC3
      hash: md5
      md5: f483e819517b72f2a49e3a1c184c7a5e.dir
      size: 4046548
      nfiles: 47
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer5000/SVC/SVC3.json
      hash: md5
      md5: 225adecb1a912ae8ac231b3f5126512a
      size: 184
  evaluate@data5-model2:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer1000"
      "SVC" "SVC3"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer1000
      hash: md5
      md5: de24f4fb97320115fd15b7d79dfb0ef4.dir
      size: 10489890
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer1000/SVC/SVC3
      hash: md5
      md5: 7504f5f73aa325e3b4253428fbcccef6.dir
      size: 842397
      nfiles: 47
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer1000/SVC/SVC3.json
      hash: md5
      md5: a4fc7173fed9a1ec20ea1b565987eed6
      size: 183
  evaluate@data6-model2:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer5000"
      "SVC" "SVC3"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer5000
      hash: md5
      md5: 397b9e47e1cbca601658f751b4b96840.dir
      size: 18137919
      nfiles: 1
    - path: imports_validator/evaluate/SVC.txt
      hash: md5
      md5: 9bc23e4aade47a8f1d641d0b59a36789
      size: 16
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 9811e6caa4e430631a3eefe9c4acfc34
      size: 1655
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer5000/SVC/SVC3
      hash: md5
      md5: 25c4870274ddf41754cf39d9d63067c4.dir
      size: 4042401
      nfiles: 47
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer5000/SVC/SVC3.json
      hash: md5
      md5: 68d5dcd8c0783afd8919451b6d25a8af
      size: 183
  evaluate@data7-model2:
    cmd: python scripts/evaluate.py "RpTweetsXS" "TweetNormalization" "TfidfVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/RpTweetsXS/TweetNormalization_TfidfVectorizer5000
      hash: md5
      md5: ec59dcd0b1cc366c46eb199ba75082da.dir
      size: 1071534776
      nfiles: 4
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 7aaf7cc6efef9247674ad408ead83a71
      size: 3971
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: results/RpTweetsXS_TweetNormalization_TfidfVectorizer5000_MLP_MLP1.json
      hash: md5
      md5: f5772902fca3463778529f92ae3a33c4
      size: 497
  evaluate@data8-model0:
    cmd: python scripts/evaluate.py "MsTweetsV2" "LemmatizerSM" "CountVectorizer1000"
      "SVC" "SVC3"
    deps:
    - path: data/MsTweetsV2/LemmatizerSM_CountVectorizer1000
      hash: md5
      md5: 8f6504d3557538c247d83e209e9309c7.dir
      size: 773044784
      nfiles: 4
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    - path: stages/models/SVC.py
      hash: md5
      md5: 83effad05bcb21943fb1429553d87d76
      size: 1713
    outs:
    - path: results/MsTweetsV2_LemmatizerSM_CountVectorizer1000_SVC_SVC3.json
      hash: md5
      md5: fbaba5056d75c6ff8323925ea9b288ab
      size: 167
  evaluate@data8-model1:
    cmd: python scripts/evaluate.py "MsTweetsV2" "LemmatizerSM" "CountVectorizer1000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/MsTweetsV2/LemmatizerSM_CountVectorizer1000
      hash: md5
      md5: 8f6504d3557538c247d83e209e9309c7.dir
      size: 773044784
      nfiles: 4
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 95623765423b8a1e454d0874b59abbb1
      size: 3746
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: results/MsTweetsV2_LemmatizerSM_CountVectorizer1000_LogisticRegression_LR1.json
      hash: md5
      md5: 55ed617a000ce405fb8a690e403e2327
      size: 346
  evaluate@data8-model2:
    cmd: python scripts/evaluate.py "MsTweetsV2" "LemmatizerSM" "CountVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/MsTweetsV2/LemmatizerSM_CountVectorizer1000
      hash: md5
      md5: 8f6504d3557538c247d83e209e9309c7.dir
      size: 773044784
      nfiles: 4
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 7aaf7cc6efef9247674ad408ead83a71
      size: 3971
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: results/MsTweetsV2_LemmatizerSM_CountVectorizer1000_MLP_MLP1.json
      hash: md5
      md5: d181cd0f171c616ac185ce641bfd42c0
      size: 489
  evaluate@data9-model0:
    cmd: python scripts/evaluate.py "MsTweetsV2" "LemmatizerSM" "CountVectorizer5000"
      "SVC" "SVC3"
    deps:
    - path: data/MsTweetsV2/LemmatizerSM_CountVectorizer5000
      hash: md5
      md5: f24d47a910e0235b7c569f5a83f10c43.dir
      size: 3862132784
      nfiles: 4
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    - path: stages/models/SVC.py
      hash: md5
      md5: 83effad05bcb21943fb1429553d87d76
      size: 1713
    outs:
    - path: results/MsTweetsV2_LemmatizerSM_CountVectorizer5000_SVC_SVC3.json
      hash: md5
      md5: 8b54adbeb4c2f19979cb8a338a825c9c
      size: 167
  evaluate@data9-model1:
    cmd: python scripts/evaluate.py "MsTweetsV2" "LemmatizerSM" "CountVectorizer5000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/MsTweetsV2/LemmatizerSM_CountVectorizer5000
      hash: md5
      md5: f24d47a910e0235b7c569f5a83f10c43.dir
      size: 3862132784
      nfiles: 4
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 95623765423b8a1e454d0874b59abbb1
      size: 3746
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: results/MsTweetsV2_LemmatizerSM_CountVectorizer5000_LogisticRegression_LR1.json
      hash: md5
      md5: 86dee4b6486aca0cdfcb7a623e02adae
      size: 343
  evaluate@data9-model2:
    cmd: python scripts/evaluate.py "MsTweetsV2" "LemmatizerSM" "CountVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/MsTweetsV2/LemmatizerSM_CountVectorizer5000
      hash: md5
      md5: f24d47a910e0235b7c569f5a83f10c43.dir
      size: 3862132784
      nfiles: 4
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 7aaf7cc6efef9247674ad408ead83a71
      size: 3971
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: results/MsTweetsV2_LemmatizerSM_CountVectorizer5000_MLP_MLP1.json
      hash: md5
      md5: 9759bee06184b5232b404bb200585b80
      size: 489
  evaluate@data10-model0:
    cmd: python scripts/evaluate.py "MsTweetsV2" "LemmatizerSM" "TfidfVectorizer1000"
      "SVC" "SVC3"
    deps:
    - path: data/MsTweetsV2/LemmatizerSM_TfidfVectorizer1000
      hash: md5
      md5: fbbf840e915f1d569b5f272dc93b8cc9.dir
      size: 773044784
      nfiles: 4
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    - path: stages/models/SVC.py
      hash: md5
      md5: 83effad05bcb21943fb1429553d87d76
      size: 1713
    outs:
    - path: results/MsTweetsV2_LemmatizerSM_TfidfVectorizer1000_SVC_SVC3.json
      hash: md5
      md5: 1703451d8693c91f809cb154bd86d991
      size: 167
  evaluate@data10-model1:
    cmd: python scripts/evaluate.py "MsTweetsV2" "LemmatizerSM" "TfidfVectorizer1000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/MsTweetsV2/LemmatizerSM_TfidfVectorizer1000
      hash: md5
      md5: fbbf840e915f1d569b5f272dc93b8cc9.dir
      size: 773044784
      nfiles: 4
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 95623765423b8a1e454d0874b59abbb1
      size: 3746
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: results/MsTweetsV2_LemmatizerSM_TfidfVectorizer1000_LogisticRegression_LR1.json
      hash: md5
      md5: 9a73e62a56d220768293e5c91c82ddc2
      size: 346
  evaluate@data10-model2:
    cmd: python scripts/evaluate.py "MsTweetsV2" "LemmatizerSM" "TfidfVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/MsTweetsV2/LemmatizerSM_TfidfVectorizer1000
      hash: md5
      md5: fbbf840e915f1d569b5f272dc93b8cc9.dir
      size: 773044784
      nfiles: 4
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 7aaf7cc6efef9247674ad408ead83a71
      size: 3971
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: results/MsTweetsV2_LemmatizerSM_TfidfVectorizer1000_MLP_MLP1.json
      hash: md5
      md5: 1fa3317915b0ebea0dfae12a371f1c1c
      size: 489
  evaluate@data11-model0:
    cmd: python scripts/evaluate.py "MsTweetsV2" "LemmatizerSM" "TfidfVectorizer5000"
      "SVC" "SVC3"
    deps:
    - path: data/MsTweetsV2/LemmatizerSM_TfidfVectorizer5000
      hash: md5
      md5: 7e01a88930cba2b11549618d901712b0.dir
      size: 3862132784
      nfiles: 4
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    - path: stages/models/SVC.py
      hash: md5
      md5: 83effad05bcb21943fb1429553d87d76
      size: 1713
    outs:
    - path: results/MsTweetsV2_LemmatizerSM_TfidfVectorizer5000_SVC_SVC3.json
      hash: md5
      md5: 1713683e50cd749a6694d61701ad0a2c
      size: 167
  evaluate@data11-model1:
    cmd: python scripts/evaluate.py "MsTweetsV2" "LemmatizerSM" "TfidfVectorizer5000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/MsTweetsV2/LemmatizerSM_TfidfVectorizer5000
      hash: md5
      md5: 7e01a88930cba2b11549618d901712b0.dir
      size: 3862132784
      nfiles: 4
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 95623765423b8a1e454d0874b59abbb1
      size: 3746
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: results/MsTweetsV2_LemmatizerSM_TfidfVectorizer5000_LogisticRegression_LR1.json
      hash: md5
      md5: eca2012e89e4b8d64763e27e13dc9c0f
      size: 346
  evaluate@data11-model2:
    cmd: python scripts/evaluate.py "MsTweetsV2" "LemmatizerSM" "TfidfVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/MsTweetsV2/LemmatizerSM_TfidfVectorizer5000
      hash: md5
      md5: 7e01a88930cba2b11549618d901712b0.dir
      size: 3862132784
      nfiles: 4
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 7aaf7cc6efef9247674ad408ead83a71
      size: 3971
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: results/MsTweetsV2_LemmatizerSM_TfidfVectorizer5000_MLP_MLP1.json
      hash: md5
      md5: 0314592df42bc338e35f8952039be88b
      size: 488
  vectorize@12:
    cmd: python scripts/vectorize.py "Classics5Authors35Books" "DummyDatacleaner"
      "TfidfVectorizer5000"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner
      hash: md5
      md5: 4a63ab08d945b568bef9adb7cd9b9e51.dir
      size: 12349137
      nfiles: 2
    - path: imports_validator/vectorize/TfidfVectorizer5000.yaml
      hash: md5
      md5: 4b0fb66e4cd38e48297c69d9c3d4a73f
      size: 105
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/TfidfVectorizer5000.py
      hash: md5
      md5: 7fa98b1029c28853802942a4622186e6
      size: 241
    outs:
    - path: data/Classics5Authors35Books/DummyDatacleaner_TfidfVectorizer5000
      hash: md5
      md5: a6b3a40c878902b935be42c909cbff20.dir
      size: 15046398
      nfiles: 1
  vectorize@13:
    cmd: python scripts/vectorize.py "PrusVsSienkiewicz" "DummyDatacleaner" "CountVectorizer5000"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner
      hash: md5
      md5: 158cfdabbc59e3e69e52252586c898c6.dir
      size: 2944961
      nfiles: 2
    - path: imports_validator/vectorize/CountVectorizer5000.yaml
      hash: md5
      md5: 1d7228b3d4f526b074d92f9975daf866
      size: 105
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/CountVectorizer5000.py
      hash: md5
      md5: caa23a258bbb68acc496765ee07836d2
      size: 176
    outs:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_CountVectorizer5000
      hash: md5
      md5: 5e57e5a0d712467f40cfb4e426eb767c.dir
      size: 1699401
      nfiles: 1
  vectorize@14:
    cmd: python scripts/vectorize.py "PrusVsSienkiewicz" "DummyDatacleaner" "DPEBPVectorizer100Avg"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner
      hash: md5
      md5: 158cfdabbc59e3e69e52252586c898c6.dir
      size: 2944961
      nfiles: 2
    - path: imports_validator/vectorize/DPEBPVectorizer100Avg.yaml
      hash: md5
      md5: 7a36e54f419c412304594fd35c32a380
      size: 140
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/DPEBPVectorizer100Avg.py
      hash: md5
      md5: 2fc43803ca207c200729f7e9d1994a15
      size: 198
    outs:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_DPEBPVectorizer100Avg
      hash: md5
      md5: 028782c0ff2543d1ba81e0a306ceb1e3.dir
      size: 2518965
      nfiles: 1
  vectorize@15:
    cmd: python scripts/vectorize.py "PrusVsSienkiewicz" "DummyDatacleaner" "FullMorphTagVectorizer"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner
      hash: md5
      md5: 158cfdabbc59e3e69e52252586c898c6.dir
      size: 2944961
      nfiles: 2
    - path: imports_validator/vectorize/FullMorphTagVectorizer.yaml
      hash: md5
      md5: 1a5da03c53448225d41c4aaa582cb7ee
      size: 70
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/FullMorphTagVectorizer.py
      hash: md5
      md5: 54e597d41d11ec1937294a717cec71c9
      size: 2460
    outs:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_FullMorphTagVectorizer
      hash: md5
      md5: f0e55d9a452b4c0136305f7dd2047d55.dir
      size: 1719640
      nfiles: 1
  evaluate@data12-model0:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer1000"
      "SVC" "SVC3"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer1000
      hash: md5
      md5: f74393ef71428c8698f92b0519b6e555.dir
      size: 773044784
      nfiles: 4
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    - path: stages/models/SVC.py
      hash: md5
      md5: 83effad05bcb21943fb1429553d87d76
      size: 1713
    outs:
    - path: 
        results/MsTweetsV2_TweetNormalizationHashtagSkip_CountVectorizer1000_SVC_SVC3.json
      hash: md5
      md5: 96c56bf9f12b318948598960e6eb563a
      size: 184
  evaluate@data12-model1:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer1000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer1000
      hash: md5
      md5: f74393ef71428c8698f92b0519b6e555.dir
      size: 773044784
      nfiles: 4
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 95623765423b8a1e454d0874b59abbb1
      size: 3746
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: 
        results/MsTweetsV2_TweetNormalizationHashtagSkip_CountVectorizer1000_LogisticRegression_LR1.json
      hash: md5
      md5: 5f34bf198453d677f067558787904784
      size: 366
  evaluate@data12-model2:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer1000
      hash: md5
      md5: f74393ef71428c8698f92b0519b6e555.dir
      size: 773044784
      nfiles: 4
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 7aaf7cc6efef9247674ad408ead83a71
      size: 3971
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: 
        results/MsTweetsV2_TweetNormalizationHashtagSkip_CountVectorizer1000_MLP_MLP1.json
      hash: md5
      md5: c01e68710a05220db59584c48a7259c5
      size: 507
  evaluate@data13-model0:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer5000"
      "SVC" "SVC3"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer5000
      hash: md5
      md5: df352169ac0d2422035f11ac4995fd66.dir
      size: 3862132784
      nfiles: 4
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    - path: stages/models/SVC.py
      hash: md5
      md5: 83effad05bcb21943fb1429553d87d76
      size: 1713
    outs:
    - path: 
        results/MsTweetsV2_TweetNormalizationHashtagSkip_CountVectorizer5000_SVC_SVC3.json
      hash: md5
      md5: 225adecb1a912ae8ac231b3f5126512a
      size: 184
  evaluate@data13-model1:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer5000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer5000
      hash: md5
      md5: df352169ac0d2422035f11ac4995fd66.dir
      size: 3862132784
      nfiles: 4
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 95623765423b8a1e454d0874b59abbb1
      size: 3746
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: 
        results/MsTweetsV2_TweetNormalizationHashtagSkip_CountVectorizer5000_LogisticRegression_LR1.json
      hash: md5
      md5: d8b6d70a3cc13dd78e48ed5b7d7ce538
      size: 365
  evaluate@data13-model2:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer5000
      hash: md5
      md5: df352169ac0d2422035f11ac4995fd66.dir
      size: 3862132784
      nfiles: 4
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 7aaf7cc6efef9247674ad408ead83a71
      size: 3971
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: 
        results/MsTweetsV2_TweetNormalizationHashtagSkip_CountVectorizer5000_MLP_MLP1.json
      hash: md5
      md5: eca1b340df023c29aaf2dc67e8aca43d
      size: 507
  evaluate@data14-model0:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer1000"
      "SVC" "SVC3"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer1000
      hash: md5
      md5: a275ea3eabb9fb9a81825a4c14bf45cf.dir
      size: 773044784
      nfiles: 4
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    - path: stages/models/SVC.py
      hash: md5
      md5: 83effad05bcb21943fb1429553d87d76
      size: 1713
    outs:
    - path: 
        results/MsTweetsV2_TweetNormalizationHashtagSkip_TfidfVectorizer1000_SVC_SVC3.json
      hash: md5
      md5: a4fc7173fed9a1ec20ea1b565987eed6
      size: 183
  evaluate@data14-model1:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer1000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer1000
      hash: md5
      md5: a275ea3eabb9fb9a81825a4c14bf45cf.dir
      size: 773044784
      nfiles: 4
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 95623765423b8a1e454d0874b59abbb1
      size: 3746
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: 
        results/MsTweetsV2_TweetNormalizationHashtagSkip_TfidfVectorizer1000_LogisticRegression_LR1.json
      hash: md5
      md5: 1bb3884f9978a80b5534cf5d490aa71d
      size: 366
  evaluate@data14-model2:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer1000
      hash: md5
      md5: a275ea3eabb9fb9a81825a4c14bf45cf.dir
      size: 773044784
      nfiles: 4
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 7aaf7cc6efef9247674ad408ead83a71
      size: 3971
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: 
        results/MsTweetsV2_TweetNormalizationHashtagSkip_TfidfVectorizer1000_MLP_MLP1.json
      hash: md5
      md5: e4da5f0112f36d2e27238b9ba03dbef7
      size: 510
  evaluate@data15-model0:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer5000"
      "SVC" "SVC3"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer5000
      hash: md5
      md5: b48c8bbe63af9d86636eb71bfb01daa2.dir
      size: 3862132784
      nfiles: 4
    - path: params/SVC3.yaml
      hash: md5
      md5: f4a38f6ad011583db9702ff247258b90
      size: 4
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    - path: stages/models/SVC.py
      hash: md5
      md5: 83effad05bcb21943fb1429553d87d76
      size: 1713
    outs:
    - path: 
        results/MsTweetsV2_TweetNormalizationHashtagSkip_TfidfVectorizer5000_SVC_SVC3.json
      hash: md5
      md5: 68d5dcd8c0783afd8919451b6d25a8af
      size: 183
  evaluate@data15-model1:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer5000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer5000
      hash: md5
      md5: b48c8bbe63af9d86636eb71bfb01daa2.dir
      size: 3862132784
      nfiles: 4
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 95623765423b8a1e454d0874b59abbb1
      size: 3746
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: 
        results/MsTweetsV2_TweetNormalizationHashtagSkip_TfidfVectorizer5000_LogisticRegression_LR1.json
      hash: md5
      md5: e695f56a7c2cc60881999ead5a1af40a
      size: 366
  evaluate@data15-model2:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer5000
      hash: md5
      md5: b48c8bbe63af9d86636eb71bfb01daa2.dir
      size: 3862132784
      nfiles: 4
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 7aaf7cc6efef9247674ad408ead83a71
      size: 3971
    - path: stages/models/Model.py
      hash: md5
      md5: 198cfbaa11881b74ecb7116946d89f9c
      size: 3249
    outs:
    - path: 
        results/MsTweetsV2_TweetNormalizationHashtagSkip_TfidfVectorizer5000_MLP_MLP1.json
      hash: md5
      md5: 55596731a7331296d8e5bc923283bb3a
      size: 507
  imports_validator:
    cmd: python imports_validator/imports_validator.py
    outs:
    - path: imports_validator/clean
      hash: md5
      md5: a6b718245c882c20262484cc7e82677d.dir
      size: 36
      nfiles: 2
    - path: imports_validator/evaluate
      hash: md5
      md5: 096e60fad046add385260adb0d2f47d4.dir
      size: 36
      nfiles: 2
    - path: imports_validator/load
      hash: md5
      md5: 2cba0f2de540bbd8e2cf65e0f986e228.dir
      size: 18
      nfiles: 1
    - path: imports_validator/md5.parquet
      hash: md5
      md5: a5ad5584954fb3580d5b59f6f00f5b3c
      size: 3707
    - path: imports_validator/vectorize
      hash: md5
      md5: 5b69aac67c99781c98b9cba6eb296eda.dir
      size: 53
      nfiles: 3
  evaluate@data0-model3:
    cmd: python scripts/evaluate.py "RpTweetsXS" "LemmatizerSM" "CountVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/RpTweetsXS/LemmatizerSM_CountVectorizer1000
      hash: md5
      md5: fa48c5b02d06f01894ce7ccf38d9431a.dir
      size: 718452
      nfiles: 1
    - path: imports_validator/evaluate/MLP.txt
      hash: md5
      md5: 7348edd09ef698996e6d75cdc52f4b88
      size: 18
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: dc1345a86fb4872844e93ec7be851d2b
      size: 3418
    outs:
    - path: mlruns_store/RpTweetsXS/LemmatizerSM/CountVectorizer1000/MLP/MLP1
      hash: md5
      md5: d3d35e354fd368faf3d19fa76b3f5ef9.dir
      size: 2481978
      nfiles: 61
    - path: results/RpTweetsXS/LemmatizerSM/CountVectorizer1000/MLP/MLP1.json
      hash: md5
      md5: b3af44c71eee1b04c2b2da4e8c2b4d14
      size: 492
  evaluate@data1-model3:
    cmd: python scripts/evaluate.py "RpTweetsXS" "TweetNormalization" "CountVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/RpTweetsXS/TweetNormalization_CountVectorizer1000
      hash: md5
      md5: 9ed3d49f1387658f33cee54f025fd443.dir
      size: 867686
      nfiles: 1
    - path: imports_validator/evaluate/MLP.txt
      hash: md5
      md5: 7348edd09ef698996e6d75cdc52f4b88
      size: 18
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: dc1345a86fb4872844e93ec7be851d2b
      size: 3418
    outs:
    - path: mlruns_store/RpTweetsXS/TweetNormalization/CountVectorizer1000/MLP/MLP1
      hash: md5
      md5: 11ecc7e99acd915ccfed6aa78713f401.dir
      size: 2483095
      nfiles: 61
    - path: results/RpTweetsXS/TweetNormalization/CountVectorizer1000/MLP/MLP1.json
      hash: md5
      md5: e226f5f065050c124a38d9191db7b929
      size: 495
  evaluate@data2-model3:
    cmd: python scripts/evaluate.py "RpTweetsXS" "LemmatizerSM" "CountVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/RpTweetsXS/LemmatizerSM_CountVectorizer5000
      hash: md5
      md5: 687dc9ab93f104cd997bbfb98f46daeb.dir
      size: 1859564
      nfiles: 1
    - path: imports_validator/evaluate/MLP.txt
      hash: md5
      md5: 7348edd09ef698996e6d75cdc52f4b88
      size: 18
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: dc1345a86fb4872844e93ec7be851d2b
      size: 3418
    outs:
    - path: mlruns_store/RpTweetsXS/LemmatizerSM/CountVectorizer5000/MLP/MLP1
      hash: md5
      md5: f525ed422c4f7593c033a105ee8a13e9.dir
      size: 12085930
      nfiles: 61
    - path: results/RpTweetsXS/LemmatizerSM/CountVectorizer5000/MLP/MLP1.json
      hash: md5
      md5: c5ce59d9a331304e06217f80510923f2
      size: 490
  evaluate@data3-model3:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer1000
      hash: md5
      md5: aae95d50927870dcaaa11ca2ebb6cf7e.dir
      size: 3267474
      nfiles: 1
    - path: imports_validator/evaluate/MLP.txt
      hash: md5
      md5: 7348edd09ef698996e6d75cdc52f4b88
      size: 18
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: dc1345a86fb4872844e93ec7be851d2b
      size: 3418
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer1000/MLP/MLP1
      hash: md5
      md5: 82ca0b52cb97ff29a896719d52f4547a.dir
      size: 2468782
      nfiles: 61
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer1000/MLP/MLP1.json
      hash: md5
      md5: 84a1edd21c2434e61c24c422ac3d14ac
      size: 508
  evaluate@data4-model3:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "CountVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_CountVectorizer5000
      hash: md5
      md5: 4b866208d010ae338c9a3365c4a3931c.dir
      size: 7565280
      nfiles: 1
    - path: imports_validator/evaluate/MLP.txt
      hash: md5
      md5: 7348edd09ef698996e6d75cdc52f4b88
      size: 18
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: dc1345a86fb4872844e93ec7be851d2b
      size: 3418
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer5000/MLP/MLP1
      hash: md5
      md5: a3c2d50aa1ad61197308981a456fa941.dir
      size: 12073788
      nfiles: 61
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/CountVectorizer5000/MLP/MLP1.json
      hash: md5
      md5: e986f52523a26725e4ebe330287735e0
      size: 506
  evaluate@data5-model3:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer1000
      hash: md5
      md5: de24f4fb97320115fd15b7d79dfb0ef4.dir
      size: 10489890
      nfiles: 1
    - path: imports_validator/evaluate/MLP.txt
      hash: md5
      md5: 7348edd09ef698996e6d75cdc52f4b88
      size: 18
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: dc1345a86fb4872844e93ec7be851d2b
      size: 3418
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer1000/MLP/MLP1
      hash: md5
      md5: c198ab15c80b71f50c2a9923b0a0b7f7.dir
      size: 2469853
      nfiles: 61
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer1000/MLP/MLP1.json
      hash: md5
      md5: c028ed16f2cb2f8780c2d08c9531cd98
      size: 508
  evaluate@data6-model3:
    cmd: python scripts/evaluate.py "MsTweetsV2" "TweetNormalizationHashtagSkip" "TfidfVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/MsTweetsV2/TweetNormalizationHashtagSkip_TfidfVectorizer5000
      hash: md5
      md5: 397b9e47e1cbca601658f751b4b96840.dir
      size: 18137919
      nfiles: 1
    - path: imports_validator/evaluate/MLP.txt
      hash: md5
      md5: 7348edd09ef698996e6d75cdc52f4b88
      size: 18
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: dc1345a86fb4872844e93ec7be851d2b
      size: 3418
    outs:
    - path: 
        mlruns_store/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer5000/MLP/MLP1
      hash: md5
      md5: cb0a906e9901e2a10359868f8f682653.dir
      size: 12068048
      nfiles: 61
    - path: 
        results/MsTweetsV2/TweetNormalizationHashtagSkip/TfidfVectorizer5000/MLP/MLP1.json
      hash: md5
      md5: 6ea4b1fa6f569d111591e1053390cc49
      size: 508
  evaluate_classification@data0-model0:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "CountVectorizer1000"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_CountVectorizer1000
      hash: md5
      md5: b7cccd92c364753e0d4cfdfbeb1b591a.dir
      size: 1567069
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/CountVectorizer1000/RandomForest/RandomForest1
      hash: md5
      md5: 74c5258edcefb8fc78d593fcaefb1aa5.dir
      size: 17555217
      nfiles: 58
    - path: 
        results/WritingStyle/DummyDatacleaner/CountVectorizer1000/RandomForest/RandomForest1.json
      hash: md5
      md5: da9d7f7bd064b8400ff3c2bf5093f729
      size: 303
  evaluate_classification@data0-model1:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "CountVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_CountVectorizer1000
      hash: md5
      md5: b7cccd92c364753e0d4cfdfbeb1b591a.dir
      size: 1567069
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: mlruns_store/WritingStyle/DummyDatacleaner/CountVectorizer1000/MLP/MLP1
      hash: md5
      md5: ee16dfbcfa23da49f9302596c0c78f33.dir
      size: 2571468
      nfiles: 64
    - path: results/WritingStyle/DummyDatacleaner/CountVectorizer1000/MLP/MLP1.json
      hash: md5
      md5: e7a594b1ebaea3825a0cc994730ff83b
      size: 464
  evaluate_classification@data0-model2:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "CountVectorizer1000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_CountVectorizer1000
      hash: md5
      md5: b7cccd92c364753e0d4cfdfbeb1b591a.dir
      size: 1567069
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/CountVectorizer1000/LogisticRegression/LR1
      hash: md5
      md5: ad59e07fba3d0aebc414af622a6f89e4.dir
      size: 151659
      nfiles: 55
    - path: 
        results/WritingStyle/DummyDatacleaner/CountVectorizer1000/LogisticRegression/LR1.json
      hash: md5
      md5: 28af19d8e1494f79e3313f2ac594bd71
      size: 351
  evaluate_classification@data1-model0:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "CountVectorizer5000"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_CountVectorizer5000
      hash: md5
      md5: d01e692423534333f4c5a9ea7dc888a1.dir
      size: 3293511
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/CountVectorizer5000/RandomForest/RandomForest1
      hash: md5
      md5: 335e8f9d574e5a937eb73879cf5792e5.dir
      size: 17433686
      nfiles: 58
    - path: 
        results/WritingStyle/DummyDatacleaner/CountVectorizer5000/RandomForest/RandomForest1.json
      hash: md5
      md5: 745b29c761157b9baae8c2bb621453da
      size: 303
  evaluate_classification@data1-model1:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "CountVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_CountVectorizer5000
      hash: md5
      md5: d01e692423534333f4c5a9ea7dc888a1.dir
      size: 3293511
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: mlruns_store/WritingStyle/DummyDatacleaner/CountVectorizer5000/MLP/MLP1
      hash: md5
      md5: a4be97cfa38059f91643a1ab3ccf3d47.dir
      size: 12162964
      nfiles: 64
    - path: results/WritingStyle/DummyDatacleaner/CountVectorizer5000/MLP/MLP1.json
      hash: md5
      md5: 2740c4b5d2441d543351fa8949e157ec
      size: 463
  evaluate_classification@data1-model2:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "CountVectorizer5000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_CountVectorizer5000
      hash: md5
      md5: d01e692423534333f4c5a9ea7dc888a1.dir
      size: 3293511
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/CountVectorizer5000/LogisticRegression/LR1
      hash: md5
      md5: b4f04041c2993b1b58fd6e87ccab2dfc.dir
      size: 171472
      nfiles: 55
    - path: 
        results/WritingStyle/DummyDatacleaner/CountVectorizer5000/LogisticRegression/LR1.json
      hash: md5
      md5: 453d98ca774e7ba5e4a9524e67acd77b
      size: 352
  evaluate_classification@data2-model0:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "TfidfVectorizer1000"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: 37f2f084cb60c8096d9987a437728788.dir
      size: 7341646
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/TfidfVectorizer1000/RandomForest/RandomForest1
      hash: md5
      md5: 208fa191f4de4c64f3c53b07d0c604f3.dir
      size: 14138059
      nfiles: 58
    - path: 
        results/WritingStyle/DummyDatacleaner/TfidfVectorizer1000/RandomForest/RandomForest1.json
      hash: md5
      md5: 456e92b5f179dc7bfb3b8ad467f32f8d
      size: 304
  evaluate_classification@data2-model1:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "TfidfVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: 37f2f084cb60c8096d9987a437728788.dir
      size: 7341646
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: mlruns_store/WritingStyle/DummyDatacleaner/TfidfVectorizer1000/MLP/MLP1
      hash: md5
      md5: f3797c8f34e716704c6934924e44ed6d.dir
      size: 2571966
      nfiles: 64
    - path: results/WritingStyle/DummyDatacleaner/TfidfVectorizer1000/MLP/MLP1.json
      hash: md5
      md5: 44351c5fddabc774fa18bcf1d5ec0726
      size: 464
  evaluate_classification@data2-model2:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "TfidfVectorizer1000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: 37f2f084cb60c8096d9987a437728788.dir
      size: 7341646
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/TfidfVectorizer1000/LogisticRegression/LR1
      hash: md5
      md5: 5dc4e99dfe2178bbaf7bafccff033bff.dir
      size: 155075
      nfiles: 55
    - path: 
        results/WritingStyle/DummyDatacleaner/TfidfVectorizer1000/LogisticRegression/LR1.json
      hash: md5
      md5: 3f13019583471d1138fc1caa020aec4e
      size: 351
  evaluate_classification@data2-model3:
    cmd: python scripts/evaluate.py "TweeterCyberbullying" "DummyDatacleaner" "DPEBPVectorizer100Avg"
      "SVC" "SVC1"
    deps:
    - path: data/TweeterCyberbullying/DummyDatacleaner_DPEBPVectorizer100Avg
      hash: md5
      md5: 58cf41efaa7dc824aa1107359e176568.dir
      size: 3709892
      nfiles: 1
    - path: imports_validator/evaluate/SVC.yaml
      hash: md5
      md5: 60891a7182cc29d128dfa18da1c0ab4e
      size: 108
    - path: params/SVC1.yaml
      hash: md5
      md5: 60666bdd5cdb9c1bfa8ed6336d21f015
      size: 24
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 09fb99c43a91014211c0584c952e12d2
      size: 1429
    outs:
    - path: 
        mlruns_store/TweeterCyberbullying/DummyDatacleaner/DPEBPVectorizer100Avg/SVC/SVC1
      hash: md5
      md5: 5dbbcc913ce6f9e3bca33d3cf54d0b8c.dir
      size: 2773631
      nfiles: 55
    - path: 
        results/TweeterCyberbullying/DummyDatacleaner/DPEBPVectorizer100Avg/SVC/SVC1.json
      hash: md5
      md5: b8abedb02468ad529ff78f10c70e8430
      size: 313
  evaluate_classification@data3-model0:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "TfidfVectorizer5000"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_TfidfVectorizer5000
      hash: md5
      md5: 3799bc8deb06cc3f5dedbb007eca2905.dir
      size: 11710062
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/TfidfVectorizer5000/RandomForest/RandomForest1
      hash: md5
      md5: d53703ca79f48b361daef72137c2efbc.dir
      size: 14693579
      nfiles: 58
    - path: 
        results/WritingStyle/DummyDatacleaner/TfidfVectorizer5000/RandomForest/RandomForest1.json
      hash: md5
      md5: 7200afe92dd7120455729b59ea2719a4
      size: 304
  evaluate_classification@data3-model1:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "TfidfVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_TfidfVectorizer5000
      hash: md5
      md5: 3799bc8deb06cc3f5dedbb007eca2905.dir
      size: 11710062
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: mlruns_store/WritingStyle/DummyDatacleaner/TfidfVectorizer5000/MLP/MLP1
      hash: md5
      md5: e4df129d484a341a06feecdb1d3e9710.dir
      size: 12161348
      nfiles: 64
    - path: results/WritingStyle/DummyDatacleaner/TfidfVectorizer5000/MLP/MLP1.json
      hash: md5
      md5: 6b1f5b3b87cf806f26513d3589abdb20
      size: 464
  evaluate_classification@data3-model2:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "TfidfVectorizer5000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_TfidfVectorizer5000
      hash: md5
      md5: 3799bc8deb06cc3f5dedbb007eca2905.dir
      size: 11710062
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/TfidfVectorizer5000/LogisticRegression/LR1
      hash: md5
      md5: 70877dd5160ab739d0bc4d6557eb5cd4.dir
      size: 182884
      nfiles: 55
    - path: 
        results/WritingStyle/DummyDatacleaner/TfidfVectorizer5000/LogisticRegression/LR1.json
      hash: md5
      md5: ee827ff8bb9f53aa3eb7cd2be2173f12
      size: 351
  evaluate_classification@data3-model3:
    cmd: python scripts/evaluate.py "TweeterCyberbullying" "DummyDatacleaner" "HerbertVectorizer"
      "SVC" "SVC1"
    deps:
    - path: data/TweeterCyberbullying/DummyDatacleaner_HerbertVectorizer
      hash: md5
      md5: 1a50cd57f8f9150dd4287cfc10279aba.dir
      size: 28345442
      nfiles: 1
    - path: imports_validator/evaluate/SVC.yaml
      hash: md5
      md5: 60891a7182cc29d128dfa18da1c0ab4e
      size: 108
    - path: params/SVC1.yaml
      hash: md5
      md5: 60666bdd5cdb9c1bfa8ed6336d21f015
      size: 24
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 09fb99c43a91014211c0584c952e12d2
      size: 1429
    outs:
    - path: mlruns_store/TweeterCyberbullying/DummyDatacleaner/HerbertVectorizer/SVC/SVC1
      hash: md5
      md5: 8fdf8197052497102a0a937eacae93cc.dir
      size: 18351360
      nfiles: 55
    - path: results/TweeterCyberbullying/DummyDatacleaner/HerbertVectorizer/SVC/SVC1.json
      hash: md5
      md5: 0f518e2841bbd08926083c48a3f8a3d5
      size: 309
  evaluate_classification@data0-model3:
    cmd: python scripts/evaluate.py "TweeterCyberbullying" "DummyDatacleaner" "BigramMorphTagVectorizer370"
      "SVC" "SVC1"
    deps:
    - path: data/TweeterCyberbullying/DummyDatacleaner_BigramMorphTagVectorizer370
      hash: md5
      md5: 007ab4c8ce8ff1bde6769ce9de00e6d3.dir
      size: 28484670
      nfiles: 1
    - path: imports_validator/evaluate/SVC.yaml
      hash: md5
      md5: 60891a7182cc29d128dfa18da1c0ab4e
      size: 108
    - path: params/SVC1.yaml
      hash: md5
      md5: 60666bdd5cdb9c1bfa8ed6336d21f015
      size: 24
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 09fb99c43a91014211c0584c952e12d2
      size: 1429
    outs:
    - path: 
        mlruns_store/TweeterCyberbullying/DummyDatacleaner/BigramMorphTagVectorizer370/SVC/SVC1
      hash: md5
      md5: b1807cacd7ec57747a5f97b4fa89a94f.dir
      size: 15109345
      nfiles: 55
    - path: 
        results/TweeterCyberbullying/DummyDatacleaner/BigramMorphTagVectorizer370/SVC/SVC1.json
      hash: md5
      md5: c7168ebce15d738bda623d4d0c931393
      size: 319
  evaluate_classification@data1-model3:
    cmd: python scripts/evaluate.py "TweeterCyberbullying" "DummyDatacleaner" "CountVectorizer1000"
      "SVC" "SVC1"
    deps:
    - path: data/TweeterCyberbullying/DummyDatacleaner_CountVectorizer1000
      hash: md5
      md5: fc0d54492a474b63083915463da3b502.dir
      size: 258966
      nfiles: 1
    - path: imports_validator/evaluate/SVC.yaml
      hash: md5
      md5: 60891a7182cc29d128dfa18da1c0ab4e
      size: 108
    - path: params/SVC1.yaml
      hash: md5
      md5: 60666bdd5cdb9c1bfa8ed6336d21f015
      size: 24
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 09fb99c43a91014211c0584c952e12d2
      size: 1429
    outs:
    - path: mlruns_store/TweeterCyberbullying/DummyDatacleaner/CountVectorizer1000/SVC/SVC1
      hash: md5
      md5: 54049fb593d0312cc62639e44e6d0f99.dir
      size: 35282627
      nfiles: 55
    - path: results/TweeterCyberbullying/DummyDatacleaner/CountVectorizer1000/SVC/SVC1.json
      hash: md5
      md5: 56292fa99f3d17e8e9c2c189980731f2
      size: 311
  evaluate_classification@data4-model0:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "BigramMorphTagVectorizer100"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_BigramMorphTagVectorizer100
      hash: md5
      md5: f439d91af2a373de91f144c1faba296d.dir
      size: 7479969
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/BigramMorphTagVectorizer100/RandomForest/RandomForest1
      hash: md5
      md5: 7dab570c7890a398b59fe6eb0e022602.dir
      size: 12611103
      nfiles: 58
    - path: 
        results/WritingStyle/DummyDatacleaner/BigramMorphTagVectorizer100/RandomForest/RandomForest1.json
      hash: md5
      md5: a70248f3117410c93a945de131120c38
      size: 310
  evaluate_classification@data4-model1:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "BigramMorphTagVectorizer100"
      "MLP" "MLP1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_BigramMorphTagVectorizer100
      hash: md5
      md5: f439d91af2a373de91f144c1faba296d.dir
      size: 7479969
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: mlruns_store/WritingStyle/DummyDatacleaner/BigramMorphTagVectorizer100/MLP/MLP1
      hash: md5
      md5: 153b6574cdf16347fd6a970be2649612.dir
      size: 434460
      nfiles: 64
    - path: results/WritingStyle/DummyDatacleaner/BigramMorphTagVectorizer100/MLP/MLP1.json
      hash: md5
      md5: bf7218a0af00745ba0ba394110718bbc
      size: 472
  evaluate_classification@data4-model2:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "BigramMorphTagVectorizer100"
      "LogisticRegression" "LR1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_BigramMorphTagVectorizer100
      hash: md5
      md5: f439d91af2a373de91f144c1faba296d.dir
      size: 7479969
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/BigramMorphTagVectorizer100/LogisticRegression/LR1
      hash: md5
      md5: fbca24077fab234dfdfa4314f58b1bcb.dir
      size: 162048
      nfiles: 55
    - path: 
        results/WritingStyle/DummyDatacleaner/BigramMorphTagVectorizer100/LogisticRegression/LR1.json
      hash: md5
      md5: e406d1eff3f96ed87d156e4837457270
      size: 360
  evaluate_classification@data4-model3:
    cmd: python scripts/evaluate.py "TweeterCyberbullying" "DummyDatacleaner" "TfidfVectorizer1000"
      "SVC" "SVC1"
    deps:
    - path: data/TweeterCyberbullying/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: ff529485d80d12eaadd86dfd61a0986c.dir
      size: 773982
      nfiles: 1
    - path: imports_validator/evaluate/SVC.yaml
      hash: md5
      md5: 60891a7182cc29d128dfa18da1c0ab4e
      size: 108
    - path: params/SVC1.yaml
      hash: md5
      md5: 60666bdd5cdb9c1bfa8ed6336d21f015
      size: 24
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 09fb99c43a91014211c0584c952e12d2
      size: 1429
    outs:
    - path: mlruns_store/TweeterCyberbullying/DummyDatacleaner/TfidfVectorizer1000/SVC/SVC1
      hash: md5
      md5: 6528fe028d7135076b60bb3161d0c1d1.dir
      size: 35329951
      nfiles: 55
    - path: results/TweeterCyberbullying/DummyDatacleaner/TfidfVectorizer1000/SVC/SVC1.json
      hash: md5
      md5: f5d67d26f25fb07d80fbef8a0ad752e4
      size: 311
  evaluate_classification@data5-model0:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "BigramMorphTagVectorizer370"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_BigramMorphTagVectorizer370
      hash: md5
      md5: 148881352428f8e7adee21ba13f37c3e.dir
      size: 27675617
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/BigramMorphTagVectorizer370/RandomForest/RandomForest1
      hash: md5
      md5: 6f0f38696fb73940f3330f7db69490f9.dir
      size: 11759115
      nfiles: 58
    - path: 
        results/WritingStyle/DummyDatacleaner/BigramMorphTagVectorizer370/RandomForest/RandomForest1.json
      hash: md5
      md5: 20a3107f945f9e707d2e7b240272cdb9
      size: 312
  evaluate_classification@data5-model1:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "BigramMorphTagVectorizer370"
      "MLP" "MLP1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_BigramMorphTagVectorizer370
      hash: md5
      md5: 148881352428f8e7adee21ba13f37c3e.dir
      size: 27675617
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: mlruns_store/WritingStyle/DummyDatacleaner/BigramMorphTagVectorizer370/MLP/MLP1
      hash: md5
      md5: 396b3dff34b274c00328b7d50b68e712.dir
      size: 1070302
      nfiles: 64
    - path: results/WritingStyle/DummyDatacleaner/BigramMorphTagVectorizer370/MLP/MLP1.json
      hash: md5
      md5: 03f8bad60a782e5a09075ecad61ffa4d
      size: 472
  evaluate_classification@data5-model2:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "BigramMorphTagVectorizer370"
      "LogisticRegression" "LR1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_BigramMorphTagVectorizer370
      hash: md5
      md5: 148881352428f8e7adee21ba13f37c3e.dir
      size: 27675617
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/BigramMorphTagVectorizer370/LogisticRegression/LR1
      hash: md5
      md5: 13e02c15e4158e4b3f1f9bcd0ee1b5bd.dir
      size: 163487
      nfiles: 55
    - path: 
        results/WritingStyle/DummyDatacleaner/BigramMorphTagVectorizer370/LogisticRegression/LR1.json
      hash: md5
      md5: c5f5e8e69cfa66400c35d04eb55ae707
      size: 360
  evaluate_classification@data5-model3:
    cmd: python scripts/evaluate.py "TweeterCyberbullying" "DummyDatacleaner" "StyloMetrix"
      "SVC" "SVC1"
    deps:
    - path: data/TweeterCyberbullying/DummyDatacleaner_StyloMetrix
      hash: md5
      md5: 5a1cce29d4fd04ebe3ae6f4840a48ef3.dir
      size: 969234
      nfiles: 1
    - path: imports_validator/evaluate/SVC.yaml
      hash: md5
      md5: 60891a7182cc29d128dfa18da1c0ab4e
      size: 108
    - path: params/SVC1.yaml
      hash: md5
      md5: 60666bdd5cdb9c1bfa8ed6336d21f015
      size: 24
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/SVC.py
      hash: md5
      md5: 09fb99c43a91014211c0584c952e12d2
      size: 1429
    outs:
    - path: mlruns_store/TweeterCyberbullying/DummyDatacleaner/StyloMetrix/SVC/SVC1
      hash: md5
      md5: 787c8193bd7afecb5e14304e6c21d88c.dir
      size: 4952920
      nfiles: 55
    - path: results/TweeterCyberbullying/DummyDatacleaner/StyloMetrix/SVC/SVC1.json
      hash: md5
      md5: bb4a5e74b8b6e5f32af6779b1093f852
      size: 302
  vectorize@16:
    cmd: python scripts/vectorize.py "PrusVsSienkiewicz" "DummyDatacleaner" "SpacyMorphTagVectorizer"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner
      hash: md5
      md5: 158cfdabbc59e3e69e52252586c898c6.dir
      size: 2944961
      nfiles: 2
    - path: imports_validator/vectorize/SpacyMorphTagVectorizer.yaml
      hash: md5
      md5: 1a5da03c53448225d41c4aaa582cb7ee
      size: 70
    - path: scripts/vectorize.py
      hash: md5
      md5: 9e08d7c90656667702d005a49f49ecba
      size: 769
    - path: stages/vectorizers/SpacyMorphTagVectorizer.py
      hash: md5
      md5: 1c494b8efa04cd654322aafe26bd093c
      size: 3511
    outs:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_SpacyMorphTagVectorizer
      hash: md5
      md5: 8e8e953d5f8fa8cb5db3b983c35e5563.dir
      size: 1350270
      nfiles: 1
  vectorize@17:
    cmd: python scripts/vectorize.py "PrusVsSienkiewicz" "DummyDatacleaner" "HerbertVectorizer"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner
      hash: md5
      md5: c20c745424c80693041364a9aa3d3851.dir
      size: 2944961
      nfiles: 2
    - path: imports_validator/vectorize/HerbertVectorizer.yaml
      hash: md5
      md5: 07fdc8076d8564e88fbe4d6f2e309664
      size: 108
    - path: scripts/vectorize.py
      hash: md5
      md5: 313deb9b0c0dc175f52248c04ddc2330
      size: 798
    - path: stages/vectorizers/HerbertVectorizer.py
      hash: md5
      md5: d3b6716ba8a17b5321c15e3d3e2ab323
      size: 4301
    outs:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_HerbertVectorizer
      hash: md5
      md5: 1c04cb2c18c61b575a4260d160c25112.dir
      size: 19330622
      nfiles: 1
  vectorize@18:
    cmd: python scripts/vectorize.py "PrusVsSienkiewicz" "DummyDatacleaner" "SpacyMorphTagVectorizer"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner
      hash: md5
      md5: c20c745424c80693041364a9aa3d3851.dir
      size: 2944961
      nfiles: 2
    - path: imports_validator/vectorize/SpacyMorphTagVectorizer.yaml
      hash: md5
      md5: cc23219eb6d307148c9fa7dbea18a081
      size: 72
    - path: scripts/vectorize.py
      hash: md5
      md5: 313deb9b0c0dc175f52248c04ddc2330
      size: 798
    - path: stages/vectorizers/SpacyMorphTagVectorizer.py
      hash: md5
      md5: 32c4f1377b287e024f0f92b9938e8b2e
      size: 3556
    outs:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_SpacyMorphTagVectorizer
      hash: md5
      md5: a5282a23b176530493073144c89460ae.dir
      size: 1350270
      nfiles: 1
  vectorize@19:
    cmd: python scripts/vectorize.py "PrusVsSienkiewicz" "DummyDatacleaner" "StyloMetrix"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner
      hash: md5
      md5: c20c745424c80693041364a9aa3d3851.dir
      size: 2944961
      nfiles: 2
    - path: imports_validator/vectorize/StyloMetrix.yaml
      hash: md5
      md5: cc23219eb6d307148c9fa7dbea18a081
      size: 72
    - path: scripts/vectorize.py
      hash: md5
      md5: 313deb9b0c0dc175f52248c04ddc2330
      size: 798
    - path: stages/vectorizers/StyloMetrix.py
      hash: md5
      md5: baf3e05871069c273f595354b5626734
      size: 715
    outs:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_StyloMetrix
      hash: md5
      md5: 5d037f3ee43b9e230f36638fb540a778.dir
      size: 1996472
      nfiles: 1
  vectorize@20:
    cmd: python scripts/vectorize.py "PrusVsSienkiewicz" "DummyDatacleaner" "TfidfVectorizer1000"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner
      hash: md5
      md5: c20c745424c80693041364a9aa3d3851.dir
      size: 2944961
      nfiles: 2
    - path: imports_validator/vectorize/TfidfVectorizer1000.yaml
      hash: md5
      md5: 249c307b2d055740eb622bcc6d40d2fb
      size: 108
    - path: scripts/vectorize.py
      hash: md5
      md5: 313deb9b0c0dc175f52248c04ddc2330
      size: 798
    - path: stages/vectorizers/TfidfVectorizer1000.py
      hash: md5
      md5: 68cd77ee60169f068587a4e7bbaabdce
      size: 252
    outs:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: e26aaf78b898c21add60e1907319ed9a.dir
      size: 3711771
      nfiles: 1
  vectorize@21:
    cmd: python scripts/vectorize.py "PrusVsSienkiewicz" "DummyDatacleaner" "TfidfVectorizer5000"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner
      hash: md5
      md5: c20c745424c80693041364a9aa3d3851.dir
      size: 2944961
      nfiles: 2
    - path: imports_validator/vectorize/TfidfVectorizer5000.yaml
      hash: md5
      md5: 249c307b2d055740eb622bcc6d40d2fb
      size: 108
    - path: scripts/vectorize.py
      hash: md5
      md5: 313deb9b0c0dc175f52248c04ddc2330
      size: 798
    - path: stages/vectorizers/TfidfVectorizer5000.py
      hash: md5
      md5: a262d3b84d8d9928c9cef04eac811201
      size: 252
    outs:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_TfidfVectorizer5000
      hash: md5
      md5: 30c26e1dab5cad198e4d82e6194249fe.dir
      size: 5708440
      nfiles: 1
  evaluate_classification@data6-model0:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "DPEBPVectorizer100Avg"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_DPEBPVectorizer100Avg
      hash: md5
      md5: bd5575da392b5d72cb810f0bb282478b.dir
      size: 3621783
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/DPEBPVectorizer100Avg/RandomForest/RandomForest1
      hash: md5
      md5: ffd978402abcaf6308bacc70932dd3d1.dir
      size: 9435370
      nfiles: 58
    - path: 
        results/WritingStyle/DummyDatacleaner/DPEBPVectorizer100Avg/RandomForest/RandomForest1.json
      hash: md5
      md5: 5604944ddd25b525a736f3f9b55f2daf
      size: 306
  evaluate_classification@data6-model1:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "DPEBPVectorizer100Avg"
      "MLP" "MLP1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_DPEBPVectorizer100Avg
      hash: md5
      md5: bd5575da392b5d72cb810f0bb282478b.dir
      size: 3621783
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: mlruns_store/WritingStyle/DummyDatacleaner/DPEBPVectorizer100Avg/MLP/MLP1
      hash: md5
      md5: 6b475fb6f211163147ab60a19006d66d.dir
      size: 298837
      nfiles: 64
    - path: results/WritingStyle/DummyDatacleaner/DPEBPVectorizer100Avg/MLP/MLP1.json
      hash: md5
      md5: 78960913b46b4e121285caf9e9dc5a81
      size: 465
  evaluate_classification@data6-model2:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "DPEBPVectorizer100Avg"
      "LogisticRegression" "LR1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_DPEBPVectorizer100Avg
      hash: md5
      md5: bd5575da392b5d72cb810f0bb282478b.dir
      size: 3621783
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/DPEBPVectorizer100Avg/LogisticRegression/LR1
      hash: md5
      md5: 264d7f6d032092926f6b3164412ddc67.dir
      size: 159919
      nfiles: 55
    - path: 
        results/WritingStyle/DummyDatacleaner/DPEBPVectorizer100Avg/LogisticRegression/LR1.json
      hash: md5
      md5: 2a6fc7c42f797fd27dfc0a3f97a93965
      size: 354
  evaluate_classification@data7-model0:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "FullMorphTagVectorizer"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_FullMorphTagVectorizer
      hash: md5
      md5: 9ea3b495a26cc6e9a6814e5f2dfaf5de.dir
      size: 3281342
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/FullMorphTagVectorizer/RandomForest/RandomForest1
      hash: md5
      md5: ada257268bea04e1c9bdf139ea96b22c.dir
      size: 15655355
      nfiles: 58
    - path: 
        results/WritingStyle/DummyDatacleaner/FullMorphTagVectorizer/RandomForest/RandomForest1.json
      hash: md5
      md5: 5d92523e6e34efddbbde431974cd34bb
      size: 307
  evaluate_classification@data7-model1:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "FullMorphTagVectorizer"
      "MLP" "MLP1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_FullMorphTagVectorizer
      hash: md5
      md5: 9ea3b495a26cc6e9a6814e5f2dfaf5de.dir
      size: 3281342
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: mlruns_store/WritingStyle/DummyDatacleaner/FullMorphTagVectorizer/MLP/MLP1
      hash: md5
      md5: 38c5fc487d5f939525fd941880ed63ee.dir
      size: 3623306
      nfiles: 64
    - path: results/WritingStyle/DummyDatacleaner/FullMorphTagVectorizer/MLP/MLP1.json
      hash: md5
      md5: b7cd435d9cf6beac96386277b640fec6
      size: 466
  evaluate_classification@data7-model2:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "FullMorphTagVectorizer"
      "LogisticRegression" "LR1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_FullMorphTagVectorizer
      hash: md5
      md5: 9ea3b495a26cc6e9a6814e5f2dfaf5de.dir
      size: 3281342
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/FullMorphTagVectorizer/LogisticRegression/LR1
      hash: md5
      md5: 5fa478ed60dddf52b47e5697e940ad54.dir
      size: 172604
      nfiles: 55
    - path: 
        results/WritingStyle/DummyDatacleaner/FullMorphTagVectorizer/LogisticRegression/LR1.json
      hash: md5
      md5: c5e574c851981591beededcabe696638
      size: 355
  evaluate_classification@data8-model0:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "SpacyMorphTagVectorizer"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_SpacyMorphTagVectorizer
      hash: md5
      md5: ca4951116d90f6f090f6b5335896bbf0.dir
      size: 2290253
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/SpacyMorphTagVectorizer/RandomForest/RandomForest1
      hash: md5
      md5: 6d632cb34e5d9725b7f828cf27106acf.dir
      size: 12107609
      nfiles: 58
    - path: 
        results/WritingStyle/DummyDatacleaner/SpacyMorphTagVectorizer/RandomForest/RandomForest1.json
      hash: md5
      md5: 1a728633166f721f7deaa14ca048696e
      size: 307
  evaluate_classification@data8-model1:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "SpacyMorphTagVectorizer"
      "MLP" "MLP1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_SpacyMorphTagVectorizer
      hash: md5
      md5: ca4951116d90f6f090f6b5335896bbf0.dir
      size: 2290253
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: mlruns_store/WritingStyle/DummyDatacleaner/SpacyMorphTagVectorizer/MLP/MLP1
      hash: md5
      md5: 2fbb0998e6efdaab3240972dd7f5b67a.dir
      size: 411570
      nfiles: 64
    - path: results/WritingStyle/DummyDatacleaner/SpacyMorphTagVectorizer/MLP/MLP1.json
      hash: md5
      md5: 6a12bbdfcbbbd315e08fdafb4025f4c7
      size: 467
  evaluate_classification@data8-model2:
    cmd: python scripts/evaluate.py "WritingStyle" "DummyDatacleaner" "SpacyMorphTagVectorizer"
      "LogisticRegression" "LR1"
    deps:
    - path: data/WritingStyle/DummyDatacleaner_SpacyMorphTagVectorizer
      hash: md5
      md5: ca4951116d90f6f090f6b5335896bbf0.dir
      size: 2290253
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/WritingStyle/DummyDatacleaner/SpacyMorphTagVectorizer/LogisticRegression/LR1
      hash: md5
      md5: f4bb0ce8912a64ed195fea07e6c8e358.dir
      size: 163995
      nfiles: 55
    - path: 
        results/WritingStyle/DummyDatacleaner/SpacyMorphTagVectorizer/LogisticRegression/LR1.json
      hash: md5
      md5: b416c6751bf24832c2ea4cc5fa378ddd
      size: 356
  evaluate_classification@data9-model0:
    cmd: python scripts/evaluate.py "Classics5Authors35Books" "DummyDatacleaner" "CountVectorizer1000"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner_CountVectorizer1000
      hash: md5
      md5: 7ee049b17d3e8053b2b987280e8db14f.dir
      size: 1666638
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/Classics5Authors35Books/DummyDatacleaner/CountVectorizer1000/RandomForest/RandomForest1
      hash: md5
      md5: b6fcd2db4f44708be0f1d56643cccc01.dir
      size: 13776003
      nfiles: 56
    - path: 
        results/Classics5Authors35Books/DummyDatacleaner/CountVectorizer1000/RandomForest/RandomForest1.json
      hash: md5
      md5: 2732564dccb95921bcfee33dd6f8a363
      size: 315
  evaluate_classification@data9-model1:
    cmd: python scripts/evaluate.py "Classics5Authors35Books" "DummyDatacleaner" "CountVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner_CountVectorizer1000
      hash: md5
      md5: 7ee049b17d3e8053b2b987280e8db14f.dir
      size: 1666638
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: 
        mlruns_store/Classics5Authors35Books/DummyDatacleaner/CountVectorizer1000/MLP/MLP1
      hash: md5
      md5: 65183a9db8a6df859e595fdd772dd74a.dir
      size: 2511173
      nfiles: 62
    - path: 
        results/Classics5Authors35Books/DummyDatacleaner/CountVectorizer1000/MLP/MLP1.json
      hash: md5
      md5: 525aad409c62937979e40c120a6b0a7d
      size: 475
  evaluate_classification@data9-model2:
    cmd: python scripts/evaluate.py "Classics5Authors35Books" "DummyDatacleaner" "CountVectorizer1000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner_CountVectorizer1000
      hash: md5
      md5: 7ee049b17d3e8053b2b987280e8db14f.dir
      size: 1666638
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/Classics5Authors35Books/DummyDatacleaner/CountVectorizer1000/LogisticRegression/LR1
      hash: md5
      md5: 97d9abe4dc70778aff99856dbc73bd89.dir
      size: 105851
      nfiles: 53
    - path: 
        results/Classics5Authors35Books/DummyDatacleaner/CountVectorizer1000/LogisticRegression/LR1.json
      hash: md5
      md5: 76e8a9ff48c6ebfb6ad0db0ae93328ca
      size: 363
  evaluate_classification@data10-model0:
    cmd: python scripts/evaluate.py "Classics5Authors35Books" "DummyDatacleaner" "CountVectorizer5000"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner_CountVectorizer5000
      hash: md5
      md5: d3c7b1e5f2d05bbeb79193b7588ae75e.dir
      size: 3746404
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/Classics5Authors35Books/DummyDatacleaner/CountVectorizer5000/RandomForest/RandomForest1
      hash: md5
      md5: 960bcc4663d0034eaff9fd00effa9ed3.dir
      size: 14596299
      nfiles: 56
    - path: 
        results/Classics5Authors35Books/DummyDatacleaner/CountVectorizer5000/RandomForest/RandomForest1.json
      hash: md5
      md5: 3c2128805677a5f0f5b21093a4cf1890
      size: 315
  evaluate_classification@data10-model1:
    cmd: python scripts/evaluate.py "Classics5Authors35Books" "DummyDatacleaner" "CountVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner_CountVectorizer5000
      hash: md5
      md5: d3c7b1e5f2d05bbeb79193b7588ae75e.dir
      size: 3746404
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: 
        mlruns_store/Classics5Authors35Books/DummyDatacleaner/CountVectorizer5000/MLP/MLP1
      hash: md5
      md5: 4cf875af80b65b6786cfc6381fe138dc.dir
      size: 12106881
      nfiles: 62
    - path: 
        results/Classics5Authors35Books/DummyDatacleaner/CountVectorizer5000/MLP/MLP1.json
      hash: md5
      md5: 85a1418ea3fa6d3a377bb3e6cd279e22
      size: 474
  evaluate_classification@data10-model2:
    cmd: python scripts/evaluate.py "Classics5Authors35Books" "DummyDatacleaner" "CountVectorizer5000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner_CountVectorizer5000
      hash: md5
      md5: d3c7b1e5f2d05bbeb79193b7588ae75e.dir
      size: 3746404
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/Classics5Authors35Books/DummyDatacleaner/CountVectorizer5000/LogisticRegression/LR1
      hash: md5
      md5: 4980186862320a6d302af9afb666aa66.dir
      size: 265545
      nfiles: 53
    - path: 
        results/Classics5Authors35Books/DummyDatacleaner/CountVectorizer5000/LogisticRegression/LR1.json
      hash: md5
      md5: 59b15679b5ebfa6d08d924bacc82fb98
      size: 363
  evaluate_classification@data11-model0:
    cmd: python scripts/evaluate.py "Classics5Authors35Books" "DummyDatacleaner" "TfidfVectorizer1000"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: 4c27a0564c9a8edeaebed9007d72edc9.dir
      size: 9156365
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/Classics5Authors35Books/DummyDatacleaner/TfidfVectorizer1000/RandomForest/RandomForest1
      hash: md5
      md5: 28013fcb3925edb73658e3f611d64470.dir
      size: 11953543
      nfiles: 56
    - path: 
        results/Classics5Authors35Books/DummyDatacleaner/TfidfVectorizer1000/RandomForest/RandomForest1.json
      hash: md5
      md5: 2a3db606a4abed531413f2768e89ff08
      size: 315
  evaluate_classification@data11-model1:
    cmd: python scripts/evaluate.py "Classics5Authors35Books" "DummyDatacleaner" "TfidfVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: 4c27a0564c9a8edeaebed9007d72edc9.dir
      size: 9156365
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: 
        mlruns_store/Classics5Authors35Books/DummyDatacleaner/TfidfVectorizer1000/MLP/MLP1
      hash: md5
      md5: 5946eacfc294d2a39903d33bd8005548.dir
      size: 2514457
      nfiles: 62
    - path: 
        results/Classics5Authors35Books/DummyDatacleaner/TfidfVectorizer1000/MLP/MLP1.json
      hash: md5
      md5: 42ea97b74bacdb01d7b7f41815a3d50a
      size: 475
  evaluate_classification@data11-model2:
    cmd: python scripts/evaluate.py "Classics5Authors35Books" "DummyDatacleaner" "TfidfVectorizer1000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: 4c27a0564c9a8edeaebed9007d72edc9.dir
      size: 9156365
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/Classics5Authors35Books/DummyDatacleaner/TfidfVectorizer1000/LogisticRegression/LR1
      hash: md5
      md5: e5e66c27dc556c6256f5c947fdf107e5.dir
      size: 112237
      nfiles: 53
    - path: 
        results/Classics5Authors35Books/DummyDatacleaner/TfidfVectorizer1000/LogisticRegression/LR1.json
      hash: md5
      md5: 8a83216536b4592e6ab63c29db88b665
      size: 363
  evaluate_classification@data12-model0:
    cmd: python scripts/evaluate.py "Classics5Authors35Books" "DummyDatacleaner" "TfidfVectorizer5000"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner_TfidfVectorizer5000
      hash: md5
      md5: a6b3a40c878902b935be42c909cbff20.dir
      size: 15046398
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/RandomForest.py
      hash: md5
      md5: a03a886133dd3a122e6d035cf912e744
      size: 1434
    outs:
    - path: 
        mlruns_store/Classics5Authors35Books/DummyDatacleaner/TfidfVectorizer5000/RandomForest/RandomForest1
      hash: md5
      md5: 23e142d06d4814905319503fbb409241.dir
      size: 13167697
      nfiles: 56
    - path: 
        results/Classics5Authors35Books/DummyDatacleaner/TfidfVectorizer5000/RandomForest/RandomForest1.json
      hash: md5
      md5: b82e1ed1bdc7c65adc7b8ed496fd397f
      size: 315
  evaluate_classification@data12-model1:
    cmd: python scripts/evaluate.py "Classics5Authors35Books" "DummyDatacleaner" "TfidfVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner_TfidfVectorizer5000
      hash: md5
      md5: a6b3a40c878902b935be42c909cbff20.dir
      size: 15046398
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/MLP1.yaml
      hash: md5
      md5: 57ea504cf9703ed9cabb8c0e9c5cd7fe
      size: 216
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/MLP.py
      hash: md5
      md5: 8ef7dd82559711f0bdc211218ac76aad
      size: 2308
    outs:
    - path: 
        mlruns_store/Classics5Authors35Books/DummyDatacleaner/TfidfVectorizer5000/MLP/MLP1
      hash: md5
      md5: 5dbaa1d59dd720897b2c78ea6772fb59.dir
      size: 12105096
      nfiles: 62
    - path: 
        results/Classics5Authors35Books/DummyDatacleaner/TfidfVectorizer5000/MLP/MLP1.json
      hash: md5
      md5: 62140573c45dc225b7ec87be084f9bb8
      size: 475
  evaluate_classification@data12-model2:
    cmd: python scripts/evaluate.py "Classics5Authors35Books" "DummyDatacleaner" "TfidfVectorizer5000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/Classics5Authors35Books/DummyDatacleaner_TfidfVectorizer5000
      hash: md5
      md5: a6b3a40c878902b935be42c909cbff20.dir
      size: 15046398
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 2fb850d6fa4c030c46e2528c0162acba
      size: 210
    - path: params/LR1.yaml
      hash: md5
      md5: 4dbc00b6cd480928eba0f2cf397e6105
      size: 63
    - path: scripts/evaluate.py
      hash: md5
      md5: 8a0de2831dac9ea593051a2b8d4178f2
      size: 1022
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 230e48da70d8c5aa10e07e9a9a9942fb
      size: 1189
    outs:
    - path: 
        mlruns_store/Classics5Authors35Books/DummyDatacleaner/TfidfVectorizer5000/LogisticRegression/LR1
      hash: md5
      md5: 4659405f7769614a4e24e943465ac725.dir
      size: 266516
      nfiles: 53
    - path: 
        results/Classics5Authors35Books/DummyDatacleaner/TfidfVectorizer5000/LogisticRegression/LR1.json
      hash: md5
      md5: bf30d0b7ccfc4c25ae5c35fb4dc18693
      size: 363
  evaluate_classification@data13-model0:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "CountVectorizer1000"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_CountVectorizer1000
      hash: md5
      md5: 539d7d92d2694c0ae160444aa751f9c4.dir
      size: 855210
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/RandomForest.py
      hash: md5
      md5: 571b70940a729164e78914b3a16a41f7
      size: 1476
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/CountVectorizer1000/RandomForest/RandomForest1
      hash: md5
      md5: 0d878d2eeac2b4be1ad233523219c3ff.dir
      size: 7026355
      nfiles: 58
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/CountVectorizer1000/RandomForest/RandomForest1.json
      hash: md5
      md5: 3586f4ddb570f65673e3f5c05407618d
      size: 309
  evaluate_classification@data13-model1:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "CountVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_CountVectorizer1000
      hash: md5
      md5: 539d7d92d2694c0ae160444aa751f9c4.dir
      size: 855210
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 6067b8c19fc6e2c90c0b537895233f59
      size: 2138
    outs:
    - path: mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/CountVectorizer1000/MLP/MLP1
      hash: md5
      md5: 66d31d5ef45e3f9c1d50e52d1c71606e.dir
      size: 2557954
      nfiles: 64
    - path: results/PrusVsSienkiewicz/DummyDatacleaner/CountVectorizer1000/MLP/MLP1.json
      hash: md5
      md5: 209cf09933dc9ee4345262489d58fbef
      size: 469
  evaluate_classification@data13-model2:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "CountVectorizer1000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_CountVectorizer1000
      hash: md5
      md5: 539d7d92d2694c0ae160444aa751f9c4.dir
      size: 855210
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 87c2516c2c04a251ab03a407b80ae7db
      size: 1222
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/CountVectorizer1000/LogisticRegression/LR1
      hash: md5
      md5: c37af352b437167bbe347df46002134e.dir
      size: 137467
      nfiles: 55
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/CountVectorizer1000/LogisticRegression/LR1.json
      hash: md5
      md5: f8e6f2955b0eb42b9532cdb5c56c4450
      size: 357
  evaluate_classification@data14-model0:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "CountVectorizer5000"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_CountVectorizer5000
      hash: md5
      md5: 1f8800c802ec04115ff5fb34c84765a6.dir
      size: 1699401
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/RandomForest.py
      hash: md5
      md5: 571b70940a729164e78914b3a16a41f7
      size: 1476
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/CountVectorizer5000/RandomForest/RandomForest1
      hash: md5
      md5: 2fc2815513324d577b02d96fcd1b56b9.dir
      size: 7738909
      nfiles: 58
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/CountVectorizer5000/RandomForest/RandomForest1.json
      hash: md5
      md5: 1080498481cf1732ce4238e09f740309
      size: 309
  evaluate_classification@data14-model1:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "CountVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_CountVectorizer5000
      hash: md5
      md5: 1f8800c802ec04115ff5fb34c84765a6.dir
      size: 1699401
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 6067b8c19fc6e2c90c0b537895233f59
      size: 2138
    outs:
    - path: mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/CountVectorizer5000/MLP/MLP1
      hash: md5
      md5: 6e1b13c4b4bfac4f623cc9c5bbd1f458.dir
      size: 12155995
      nfiles: 64
    - path: results/PrusVsSienkiewicz/DummyDatacleaner/CountVectorizer5000/MLP/MLP1.json
      hash: md5
      md5: dd0f8e6b8babecebd1ffdc912b1ed5d8
      size: 469
  evaluate_classification@data14-model2:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "CountVectorizer5000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_CountVectorizer5000
      hash: md5
      md5: 1f8800c802ec04115ff5fb34c84765a6.dir
      size: 1699401
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 87c2516c2c04a251ab03a407b80ae7db
      size: 1222
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/CountVectorizer5000/LogisticRegression/LR1
      hash: md5
      md5: ecb26cc707c2e5283fb40be2750bc054.dir
      size: 169445
      nfiles: 55
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/CountVectorizer5000/LogisticRegression/LR1.json
      hash: md5
      md5: 9ed438379a866aa77c6976eaf17bbb93
      size: 357
  evaluate_classification@data15-model0:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "DPEBPVectorizer100Avg"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_DPEBPVectorizer100Avg
      hash: md5
      md5: 49d8a9daa92be83c62d1911047380ce3.dir
      size: 2518903
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/RandomForest.py
      hash: md5
      md5: 571b70940a729164e78914b3a16a41f7
      size: 1476
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/DPEBPVectorizer100Avg/RandomForest/RandomForest1
      hash: md5
      md5: 43dbc9b573a1fbaa45ebd5d9483d80b5.dir
      size: 8311638
      nfiles: 58
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/DPEBPVectorizer100Avg/RandomForest/RandomForest1.json
      hash: md5
      md5: ac7f35b84cbb1b6261ca29faf72c2cb3
      size: 311
  evaluate_classification@data15-model1:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "DPEBPVectorizer100Avg"
      "MLP" "MLP1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_DPEBPVectorizer100Avg
      hash: md5
      md5: 49d8a9daa92be83c62d1911047380ce3.dir
      size: 2518903
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 6067b8c19fc6e2c90c0b537895233f59
      size: 2138
    outs:
    - path: mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/DPEBPVectorizer100Avg/MLP/MLP1
      hash: md5
      md5: 86ddc145738a2ab1631743b3601da72d.dir
      size: 306915
      nfiles: 64
    - path: results/PrusVsSienkiewicz/DummyDatacleaner/DPEBPVectorizer100Avg/MLP/MLP1.json
      hash: md5
      md5: c573cc7f91ca9aff27cdf1733efc077b
      size: 471
  evaluate_classification@data15-model2:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "DPEBPVectorizer100Avg"
      "LogisticRegression" "LR1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_DPEBPVectorizer100Avg
      hash: md5
      md5: 49d8a9daa92be83c62d1911047380ce3.dir
      size: 2518903
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 87c2516c2c04a251ab03a407b80ae7db
      size: 1222
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/DPEBPVectorizer100Avg/LogisticRegression/LR1
      hash: md5
      md5: 685bd127e27cfac71f63fcfa8f9fbd05.dir
      size: 148833
      nfiles: 55
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/DPEBPVectorizer100Avg/LogisticRegression/LR1.json
      hash: md5
      md5: 36f09e9a053c084e91f3a6c6c13a3a18
      size: 359
  evaluate_classification@data16-model0:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "FullMorphTagVectorizer"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_FullMorphTagVectorizer
      hash: md5
      md5: 0f63a3b89466fb5a390ef0546e60932a.dir
      size: 1719640
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/RandomForest.py
      hash: md5
      md5: 571b70940a729164e78914b3a16a41f7
      size: 1476
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/FullMorphTagVectorizer/RandomForest/RandomForest1
      hash: md5
      md5: 79266cef7d389765a009cb9781184f6a.dir
      size: 13502474
      nfiles: 58
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/FullMorphTagVectorizer/RandomForest/RandomForest1.json
      hash: md5
      md5: b157dd01c236f2c32d083ce3f54bbe23
      size: 312
  evaluate_classification@data16-model1:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "FullMorphTagVectorizer"
      "MLP" "MLP1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_FullMorphTagVectorizer
      hash: md5
      md5: 0f63a3b89466fb5a390ef0546e60932a.dir
      size: 1719640
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 6067b8c19fc6e2c90c0b537895233f59
      size: 2138
    outs:
    - path: mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/FullMorphTagVectorizer/MLP/MLP1
      hash: md5
      md5: 8434dbeac995af969574260facc2d69f.dir
      size: 3619487
      nfiles: 64
    - path: results/PrusVsSienkiewicz/DummyDatacleaner/FullMorphTagVectorizer/MLP/MLP1.json
      hash: md5
      md5: 74c6f7e9b19f05ab153f02222deb2a6b
      size: 472
  evaluate_classification@data16-model2:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "FullMorphTagVectorizer"
      "LogisticRegression" "LR1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_FullMorphTagVectorizer
      hash: md5
      md5: 0f63a3b89466fb5a390ef0546e60932a.dir
      size: 1719640
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 87c2516c2c04a251ab03a407b80ae7db
      size: 1222
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/FullMorphTagVectorizer/LogisticRegression/LR1
      hash: md5
      md5: 0e82114122a2a1a0f11ff339aaa8dffa.dir
      size: 153357
      nfiles: 55
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/FullMorphTagVectorizer/LogisticRegression/LR1.json
      hash: md5
      md5: 7901ba30a55260cda35c2f2a10eacd8b
      size: 359
  evaluate_classification@data17-model0:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "HerbertVectorizer"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_HerbertVectorizer
      hash: md5
      md5: 1c04cb2c18c61b575a4260d160c25112.dir
      size: 19330622
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/RandomForest.py
      hash: md5
      md5: 571b70940a729164e78914b3a16a41f7
      size: 1476
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/HerbertVectorizer/RandomForest/RandomForest1
      hash: md5
      md5: 18e52175cb87b4526c091bd8296c19d1.dir
      size: 10388130
      nfiles: 58
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/HerbertVectorizer/RandomForest/RandomForest1.json
      hash: md5
      md5: e5727de474ab0eb7d75e291cb8bc6f03
      size: 308
  evaluate_classification@data17-model1:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "HerbertVectorizer"
      "MLP" "MLP1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_HerbertVectorizer
      hash: md5
      md5: 1c04cb2c18c61b575a4260d160c25112.dir
      size: 19330622
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 6067b8c19fc6e2c90c0b537895233f59
      size: 2138
    outs:
    - path: mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/HerbertVectorizer/MLP/MLP1
      hash: md5
      md5: 7b7088028e9065e910c4cd4cbcf34d80.dir
      size: 1113080
      nfiles: 64
    - path: results/PrusVsSienkiewicz/DummyDatacleaner/HerbertVectorizer/MLP/MLP1.json
      hash: md5
      md5: 3a5e178d00fc47b2d16964c98c19beab
      size: 467
  evaluate_classification@data17-model2:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "HerbertVectorizer"
      "LogisticRegression" "LR1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_HerbertVectorizer
      hash: md5
      md5: 1c04cb2c18c61b575a4260d160c25112.dir
      size: 19330622
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 87c2516c2c04a251ab03a407b80ae7db
      size: 1222
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/HerbertVectorizer/LogisticRegression/LR1
      hash: md5
      md5: 971d68841b7c654f273ce91c9833fc5e.dir
      size: 154001
      nfiles: 55
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/HerbertVectorizer/LogisticRegression/LR1.json
      hash: md5
      md5: 7ecd01d9eb62d0d007eb188b9acb36a7
      size: 355
  evaluate_classification@data18-model0:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "SpacyMorphTagVectorizer"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_SpacyMorphTagVectorizer
      hash: md5
      md5: a5282a23b176530493073144c89460ae.dir
      size: 1350270
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/RandomForest.py
      hash: md5
      md5: 571b70940a729164e78914b3a16a41f7
      size: 1476
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/SpacyMorphTagVectorizer/RandomForest/RandomForest1
      hash: md5
      md5: 7d600aa2dec79e6b2e52e63e06e4fd3e.dir
      size: 8754518
      nfiles: 58
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/SpacyMorphTagVectorizer/RandomForest/RandomForest1.json
      hash: md5
      md5: a37464d04515461e6bfe9ca9fdf2c6fd
      size: 313
  evaluate_classification@data18-model1:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "SpacyMorphTagVectorizer"
      "MLP" "MLP1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_SpacyMorphTagVectorizer
      hash: md5
      md5: a5282a23b176530493073144c89460ae.dir
      size: 1350270
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 6067b8c19fc6e2c90c0b537895233f59
      size: 2138
    outs:
    - path: mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/SpacyMorphTagVectorizer/MLP/MLP1
      hash: md5
      md5: 7bed3d029a6e44163390a1106cd8014f.dir
      size: 410169
      nfiles: 64
    - path: results/PrusVsSienkiewicz/DummyDatacleaner/SpacyMorphTagVectorizer/MLP/MLP1.json
      hash: md5
      md5: 2c7b65ce6bf6ed45ad27cab074e4a12f
      size: 473
  evaluate_classification@data18-model2:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "SpacyMorphTagVectorizer"
      "LogisticRegression" "LR1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_SpacyMorphTagVectorizer
      hash: md5
      md5: a5282a23b176530493073144c89460ae.dir
      size: 1350270
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 87c2516c2c04a251ab03a407b80ae7db
      size: 1222
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/SpacyMorphTagVectorizer/LogisticRegression/LR1
      hash: md5
      md5: e8ef57d650cfc3af2efe5c718710cd58.dir
      size: 156426
      nfiles: 55
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/SpacyMorphTagVectorizer/LogisticRegression/LR1.json
      hash: md5
      md5: ae1b4f6092c09fe681acee252d121888
      size: 361
  evaluate_classification@data19-model0:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "StyloMetrix"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_StyloMetrix
      hash: md5
      md5: 5d037f3ee43b9e230f36638fb540a778.dir
      size: 1996472
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/RandomForest.py
      hash: md5
      md5: 571b70940a729164e78914b3a16a41f7
      size: 1476
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/StyloMetrix/RandomForest/RandomForest1
      hash: md5
      md5: 119c856a11125df43d33df3ce488a3e6.dir
      size: 9226414
      nfiles: 58
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/StyloMetrix/RandomForest/RandomForest1.json
      hash: md5
      md5: 2596a76bad6eb8b54c56169981073be7
      size: 299
  evaluate_classification@data19-model1:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "StyloMetrix"
      "MLP" "MLP1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_StyloMetrix
      hash: md5
      md5: 5d037f3ee43b9e230f36638fb540a778.dir
      size: 1996472
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 6067b8c19fc6e2c90c0b537895233f59
      size: 2138
    outs:
    - path: mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/StyloMetrix/MLP/MLP1
      hash: md5
      md5: 521162dc47802dc1dcfcd6fa4a53392b.dir
      size: 602033
      nfiles: 64
    - path: results/PrusVsSienkiewicz/DummyDatacleaner/StyloMetrix/MLP/MLP1.json
      hash: md5
      md5: 1507a3c8d97c876cfbea302a605b8917
      size: 460
  evaluate_classification@data19-model2:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "StyloMetrix"
      "LogisticRegression" "LR1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_StyloMetrix
      hash: md5
      md5: 5d037f3ee43b9e230f36638fb540a778.dir
      size: 1996472
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 87c2516c2c04a251ab03a407b80ae7db
      size: 1222
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/StyloMetrix/LogisticRegression/LR1
      hash: md5
      md5: 5dfa2a0207a60954891ab746c78dc5f8.dir
      size: 155347
      nfiles: 55
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/StyloMetrix/LogisticRegression/LR1.json
      hash: md5
      md5: 3eddb28e98be817ab14e77cff378ed04
      size: 349
  evaluate_classification@data20-model0:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "TfidfVectorizer1000"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: e26aaf78b898c21add60e1907319ed9a.dir
      size: 3711771
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/RandomForest.py
      hash: md5
      md5: 571b70940a729164e78914b3a16a41f7
      size: 1476
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/TfidfVectorizer1000/RandomForest/RandomForest1
      hash: md5
      md5: 46f31046072b307bba7b831339572cb5.dir
      size: 6047232
      nfiles: 58
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/TfidfVectorizer1000/RandomForest/RandomForest1.json
      hash: md5
      md5: 7cdbe7e007184f90cc596dd2380e7ed3
      size: 309
  evaluate_classification@data20-model1:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "TfidfVectorizer1000"
      "MLP" "MLP1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: e26aaf78b898c21add60e1907319ed9a.dir
      size: 3711771
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 6067b8c19fc6e2c90c0b537895233f59
      size: 2138
    outs:
    - path: mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/TfidfVectorizer1000/MLP/MLP1
      hash: md5
      md5: 252a5c83bcb64b7ceb896d82a1fc3368.dir
      size: 2560480
      nfiles: 64
    - path: results/PrusVsSienkiewicz/DummyDatacleaner/TfidfVectorizer1000/MLP/MLP1.json
      hash: md5
      md5: 66b7a62afe8f6635a183bbf183e2297b
      size: 467
  evaluate_classification@data20-model2:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "TfidfVectorizer1000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_TfidfVectorizer1000
      hash: md5
      md5: e26aaf78b898c21add60e1907319ed9a.dir
      size: 3711771
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 87c2516c2c04a251ab03a407b80ae7db
      size: 1222
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/TfidfVectorizer1000/LogisticRegression/LR1
      hash: md5
      md5: 054aca13d384bae54ba3ac27b7f7293d.dir
      size: 138536
      nfiles: 55
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/TfidfVectorizer1000/LogisticRegression/LR1.json
      hash: md5
      md5: e79cfd3e9ed87b08c62ce6ce64c76f90
      size: 357
  evaluate_classification@data21-model0:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "TfidfVectorizer5000"
      "RandomForest" "RandomForest1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_TfidfVectorizer5000
      hash: md5
      md5: 30c26e1dab5cad198e4d82e6194249fe.dir
      size: 5708440
      nfiles: 1
    - path: imports_validator/evaluate/RandomForest.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/RandomForest1.yaml
      hash: md5
      md5: 911fa5beb1765bda142542bfbf82b586
      size: 17
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/RandomForest.py
      hash: md5
      md5: 571b70940a729164e78914b3a16a41f7
      size: 1476
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/TfidfVectorizer5000/RandomForest/RandomForest1
      hash: md5
      md5: 2e56175633808190ae7707e148488382.dir
      size: 7136948
      nfiles: 58
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/TfidfVectorizer5000/RandomForest/RandomForest1.json
      hash: md5
      md5: c96801c95b8eb2d4e93ac704239e345e
      size: 308
  evaluate_classification@data21-model1:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "TfidfVectorizer5000"
      "MLP" "MLP1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_TfidfVectorizer5000
      hash: md5
      md5: 30c26e1dab5cad198e4d82e6194249fe.dir
      size: 5708440
      nfiles: 1
    - path: imports_validator/evaluate/MLP.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/MLP1.yaml
      hash: md5
      md5: 37c50ab93123590daa2ce4cc339014d4
      size: 224
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/MLP.py
      hash: md5
      md5: 6067b8c19fc6e2c90c0b537895233f59
      size: 2138
    outs:
    - path: mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/TfidfVectorizer5000/MLP/MLP1
      hash: md5
      md5: 8aa70fef0dc92da91aad84ada5f1c8e8.dir
      size: 12158711
      nfiles: 64
    - path: results/PrusVsSienkiewicz/DummyDatacleaner/TfidfVectorizer5000/MLP/MLP1.json
      hash: md5
      md5: 40b6d39287fd9507158f961c3a97e525
      size: 469
  evaluate_classification@data21-model2:
    cmd: python scripts/evaluate.py "PrusVsSienkiewicz" "DummyDatacleaner" "TfidfVectorizer5000"
      "LogisticRegression" "LR1"
    deps:
    - path: data/PrusVsSienkiewicz/DummyDatacleaner_TfidfVectorizer5000
      hash: md5
      md5: 30c26e1dab5cad198e4d82e6194249fe.dir
      size: 5708440
      nfiles: 1
    - path: imports_validator/evaluate/LogisticRegression.yaml
      hash: md5
      md5: 84ac76dc7d88226f0270c75f7b39ffc9
      size: 216
    - path: params/LR1.yaml
      hash: md5
      md5: 575940047794a5dc6e126056daa3ba96
      size: 67
    - path: scripts/evaluate.py
      hash: md5
      md5: ea49b7cebc0803f03157ca6696987f14
      size: 1058
    - path: stages/models/LogisticRegression.py
      hash: md5
      md5: 87c2516c2c04a251ab03a407b80ae7db
      size: 1222
    outs:
    - path: 
        mlruns_store/PrusVsSienkiewicz/DummyDatacleaner/TfidfVectorizer5000/LogisticRegression/LR1
      hash: md5
      md5: f01f22ea966f44de885e43b329786d58.dir
      size: 170963
      nfiles: 55
    - path: 
        results/PrusVsSienkiewicz/DummyDatacleaner/TfidfVectorizer5000/LogisticRegression/LR1.json
      hash: md5
      md5: 3dc7d26eb567b55927b74a2a3bd6ee5b
      size: 356
